{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings( 'ignore' )\n",
    "import gc\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import text, sequence\n",
    "\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.util import ngrams\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings( 'ignore' )\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "#from thundersvm import SVC\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, accuracy_score\n",
    "\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding\n",
    "from keras.layers import CuDNNGRU, CuDNNLSTM, Conv1D, Conv2D, Dense, Bidirectional, GRU, LSTM, MaxPool1D\n",
    "from keras.layers import SpatialDropout1D, Dropout, Concatenate, concatenate, Softmax, Flatten, Reshape\n",
    "from keras.layers import GlobalMaxPooling1D, GlobalAveragePooling1D, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.optimizers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from tensorflow.random import set_seed\n",
    "from numpy.random import seed\n",
    "import random\n",
    "\n",
    "\n",
    "seed_value = 0\n",
    "set_seed(seed_value)\n",
    "seed(seed_value)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "random.seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters for this model\n",
    "\n",
    "max_len = 150\n",
    "embed_size = 300\n",
    "pre_trained_flag = True\n",
    "embed_trainable = False\n",
    "emb_weights_init = 'glorot_normal'\n",
    "spdrpt = 0.40\n",
    "drpt = 0.2\n",
    "fc_weights_init = 'glorot_uniform'\n",
    "fc_act = 'elu'\n",
    "lr_rate = 0.001\n",
    "optimizer = 'adam'\n",
    "lstm_units = 130\n",
    "multi_gpu_flag = 0\n",
    "gpus = 2\n",
    "batch = 16\n",
    "nepochs = 10\n",
    "patience = 5\n",
    "decay = True\n",
    "decay_rate = 0.5\n",
    "decay_after = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddingfile = './General_Embeddings/glove.txt'\n",
    "#embeddingfile = './General_Embeddings/w2v_cbow.txt'\n",
    "#embeddingfile = './General_Embeddings/w2v_sg.txt'\n",
    "#embeddingfile = './General_Embeddings/ft_cbow.vec'\n",
    "embeddingfile = 'wiki-news-300d-1M.vec'\n",
    "\n",
    "embedding_matrix = []\n",
    "#max_features = 100000\n",
    "\n",
    "modelname = 'BLSTM_ft_sg'\n",
    "\n",
    "modelpath = './Models/' + modelname + '/'\n",
    "\n",
    "if not os.path.exists( modelpath ):\n",
    "    os.makedirs( modelpath )\n",
    "if not os.path.exists( './Results/' ):\n",
    "    os.makedirs( './Results/' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_lower_case(data):\n",
    "    # Convert the input text into lowercase text\n",
    "    return np.char.lower(str(data))\n",
    "\n",
    "def remove_stop_words(data):\n",
    "    # Tokenize the input text and remove stopwords from the corpus\n",
    "    stop_words = stopwords.words('english')\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in words:\n",
    "        if w not in stop_words and len(w) > 3:\n",
    "            new_text = new_text + \" \" + lemmatizer.lemmatize(w)\n",
    "    return new_text\n",
    "\n",
    "def remove_punctuation(data):\n",
    "    # Remove punctuations defined below from input text\n",
    "    symbols = \"!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n\"\n",
    "    for i in range(len(symbols)):\n",
    "        data = np.char.replace(data, symbols[i], ' ')\n",
    "        data = np.char.replace(data, \"  \", \" \")\n",
    "    data = np.char.replace(data, ',', '')\n",
    "    return data\n",
    "\n",
    "def remove_apostrophe(data):\n",
    "    # Remove apostrophe from the input text\n",
    "    return np.char.replace(data, \"'\", \"\")\n",
    "\n",
    "def preprocess(data):\n",
    "    # Preprocess the input text\n",
    "    data = convert_lower_case(data)\n",
    "    data = remove_punctuation(data) #remove comma seperately\n",
    "    data = remove_apostrophe(data)\n",
    "    data = remove_stop_words(data)\n",
    "    return data\n",
    "\n",
    "def get_tokens(dataframe, column):\n",
    "    tokens = []\n",
    "    for i in tqdm_notebook(dataframe[column][:]):\n",
    "        _tokens = word_tokenize(preprocess(str(i)))\n",
    "        tokens.append(_tokens)\n",
    "        \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5061f53f1e742efb9a0bfa15cfa0f7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=95692.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7885d7d9203b4f758d8c733357044466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=76564.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "483ed3a8e0874f08ba79cbab5eae098e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=76564.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('data\\\\wiki_train.csv')\n",
    "train_data = train_data.dropna(axis = 0)\n",
    "#train_data = train_data.sample(n=100000, random_state=0)\n",
    "train_data['toxicity'] = train_data['toxicity'].round()\n",
    "\n",
    "df_test = pd.read_csv('test_data.csv')\n",
    "df_test.loc[df_test['Label'] == 'BAD', 'Label'] = 1\n",
    "df_test.loc[df_test['Label'] == 'NOT_BAD', 'Label'] = 0\n",
    "\n",
    "\n",
    "train_feature = get_tokens(train_data, 'comment')\n",
    "train_label = train_data['toxicity']\n",
    "\n",
    "test_feature = get_tokens(df_test, 'Text')\n",
    "test_label = df_test['Label']\n",
    "\n",
    "identity_terms = []\n",
    "for i in tqdm_notebook(range(len(df_test['Text']))):\n",
    "    _comment = df_test.loc[i,  'Text'].split(\" \")\n",
    "    if len(_comment) < 3:\n",
    "        _term = _comment[1]\n",
    "        identity_terms.append(_term)\n",
    "identity_terms = list(set(identity_terms))\n",
    "\n",
    "\n",
    "terms = []\n",
    "for i in range(len(df_test['Text'])):\n",
    "    _text = df_test.loc[i, 'Text'].split(' ')\n",
    "    _term = list(set(_text).intersection(set(identity_terms)))\n",
    "    if len(_term) > 0:\n",
    "        terms.append(_term[0])\n",
    "    else:\n",
    "        terms.append(np.nan)\n",
    "        \n",
    "df_test['Identity_Terms'] = terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold( n_splits=5, random_state=0, shuffle=True )\n",
    "print(skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124996\n",
      "124996\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_feature)\n",
    "train_features = tokenizer.texts_to_sequences(train_feature)\n",
    "train_features = pad_sequences(train_features, maxlen = 128, dtype=\"int32\")\n",
    "train_features_vocab_size = len(tokenizer.word_index) + 1\n",
    "print(train_features_vocab_size)\n",
    "\n",
    "train_labels = tf.convert_to_tensor(train_label, dtype=\"int32\")\n",
    "\n",
    "test_features = tokenizer.texts_to_sequences(test_feature)\n",
    "test_features = pad_sequences(test_features, maxlen = 128, dtype=\"int32\")\n",
    "features_vocab_size = len(tokenizer.word_index) + 1\n",
    "print(features_vocab_size)\n",
    "\n",
    "test_labels = tf.convert_to_tensor(test_label, dtype=\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coefs( word, *arr ):\n",
    "    return word, np.asarray( arr, dtype='float32' )\n",
    "\n",
    "def get_vectors( tokenizer ):\n",
    "    word_index = tokenizer.word_index\n",
    "    num_words = min( len(tokenizer.word_index) + 1, len( word_index ) + 1 )\n",
    "    embedding_matrix = np.zeros( ( num_words, embed_size ) )\n",
    "    for word, i in word_index.items(  ):\n",
    "        if i >= len(tokenizer.word_index) + 1:\n",
    "            continue\n",
    "        embedding_vector = embeddings_index.get( word )\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    gc.collect()\n",
    "    return embedding_matrix\n",
    "\n",
    "if pre_trained_flag == True:\n",
    "    embeddings_index = dict( get_coefs( *o.rstrip().rsplit(' ') ) for o in open( embeddingfile, encoding='utf-8' ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "\n",
    "\n",
    "\n",
    "checkpoint_filepath = 'checkpoints/model.h5'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_false_positives',\n",
    "    mode='min',\n",
    "    save_best_only=True,\n",
    "    verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "embedding_matrix = get_vectors( tokenizer=tokenizer)\n",
    "\n",
    "inputs = tf.keras.Input(shape=(None,), dtype=\"int32\")\n",
    "\n",
    "x = tf.keras.layers.Embedding( input_dim=len(tokenizer.word_index)+1, output_dim=embed_size,\n",
    "                      weights=[embedding_matrix], trainable=embed_trainable, name='Embedding' )(inputs)\n",
    "x = tf.keras.layers.SpatialDropout1D( spdrpt, name='SpatialDropout1D' )( x )\n",
    "x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128))(x)\n",
    "x =  tf.keras.layers.Dropout( drpt, name='Dropout' )( x )\n",
    "fc1 =  tf.keras.layers.Dense( 128, activation=fc_act, kernel_initializer=fc_weights_init, name='FC1' )( x )\n",
    "fc2 = tf.keras.layers.Dense( 64, activation=fc_act, kernel_initializer=fc_weights_init, name='FC2')( fc1 )\n",
    "outputs =  tf.keras.layers.Dense( 1, activation='sigmoid', name='Output' )( fc2 )\n",
    "model = tf.keras.Model(inputs = inputs, outputs = outputs)\n",
    "\n",
    "model.compile( loss='binary_crossentropy', optimizer=optimizer, metrics = ['accuracy',tf.keras.metrics.AUC(), tf.keras.metrics.FalsePositives(thresholds=None, name=None, dtype=None)] )\n",
    "\n",
    "xtrain, xval, ytrain, yval = train_test_split( train_features, train_label, test_size=0.25, random_state=0 )\n",
    "\n",
    "hist = model.fit( xtrain, ytrain, batch_size=batch, validation_data=( xval,yval ),\n",
    "                     epochs=nepochs, verbose=1, callbacks=[model_checkpoint_callback])\n",
    "model.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('checkpoints/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22bd400ed9d743a9a7a45ad09b7dc212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=95692.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "xf_positive = 0\n",
    "xd_positive = 0\n",
    "xf_total = 0\n",
    "xd_total = 0\n",
    "\n",
    "for i in tqdm_notebook(range(len(train_feature))):\n",
    "    if(train_labels[i] == 1 and len(list(set(train_feature[i]).intersection(set(terms)))) > 0):\n",
    "        xd_positive += 1\n",
    "        xd_total += 1\n",
    "    elif(len(list(set(train_feature[i]).intersection(set(terms)))) > 0):\n",
    "        xd_total += 1\n",
    "    elif(train_labels[i] == 1 and len(list(set(train_feature[i]).intersection(set(terms))))==0):\n",
    "        xf_positive += 1\n",
    "        xf_total += 1\n",
    "    elif(len(list(set(train_feature[i]).intersection(set(terms))))== 0):\n",
    "        xf_total += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.009719561164268795"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf = xf_positive / xf_total\n",
    "pd = xd_positive / xd_total\n",
    "discrimination = pf - pd\n",
    "discrimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dec358dab0844bb8bc3978869dd9b97c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=95692.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(train_features)\n",
    "xf_positive = 0\n",
    "xd_positive = 0\n",
    "xf_total = 0\n",
    "xd_total = 0\n",
    "\n",
    "for i in tqdm_notebook(range(len(train_feature))):\n",
    "    if(pred[i].round() == 1 and len(list(set(train_feature[i]).intersection(set(terms)))) > 0):\n",
    "        xd_positive += 1\n",
    "        xd_total += 1\n",
    "    elif(len(list(set(train_feature[i]).intersection(set(terms)))) > 0):\n",
    "        xd_total += 1\n",
    "    elif(pred[i].round() == 1 and len(list(set(train_feature[i]).intersection(set(terms))))==0):\n",
    "        xf_positive += 1\n",
    "        xf_total += 1\n",
    "    elif(len(list(set(train_feature[i]).intersection(set(terms))))== 0):\n",
    "        xf_total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004362583351552665"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf = xf_positive / xf_total\n",
    "pd = xd_positive / xd_total\n",
    "discrimination = pf - pd\n",
    "discrimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8403949636905073"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(test_features)\n",
    "df_test['prediction_scores'] = pred\n",
    "accuracy_score(test_labels, pred.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7523ed6e5ad44fb9823bdeb4b254c513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=76564.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "xf_positive = 0\n",
    "xd_positive = 0\n",
    "xf_total = 0\n",
    "xd_total = 0\n",
    "\n",
    "for i in tqdm_notebook(range(len(test_feature))):\n",
    "    if(pred[i].round() == 1 and len(list(set(test_feature[i]).intersection(set(terms)))) > 0):\n",
    "        xd_positive += 1\n",
    "        xd_total += 1\n",
    "    elif(len(list(set(test_feature[i]).intersection(set(terms)))) > 0):\n",
    "        xd_total += 1\n",
    "    elif(pred[i].round() == 1 and len(list(set(test_feature[i]).intersection(set(terms))))==0):\n",
    "        xf_positive += 1\n",
    "        xf_total += 1\n",
    "    elif(len(list(set(test_feature[i]).intersection(set(terms))))== 0):\n",
    "        xf_total += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.05619392829528075"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf = xf_positive / xf_total\n",
    "pd = xd_positive / xd_total\n",
    "discrimination = pf - pd\n",
    "discrimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in  nan\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Identity_Titles</th>\n",
       "      <th>Identity_Term_False_Positive</th>\n",
       "      <th>Total_False_Positive</th>\n",
       "      <th>Identity_Term_False_Negatives</th>\n",
       "      <th>Total_False_Negative</th>\n",
       "      <th>FPR - FPRt</th>\n",
       "      <th>FNR - FNRt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>buddhist</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.354029</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.043805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>canadian</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.463672</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.153448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.221929</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.088295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>transgender</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.297226</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.012998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>african</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.357992</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.047768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>black</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.212682</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.097542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lgbtq</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.400264</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.090040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>female</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.286658</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.023566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bisexual</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.116248</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.193976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>latino</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.174373</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.135852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>straight</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.232497</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.077727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>lgbt</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.417437</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.107213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>indian</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.414795</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.104571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lesbian</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.110964</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.199260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>jewish</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.336856</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.026632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>muslim</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.346103</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.035879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>european</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.368560</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.058336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>younger</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.414795</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.104571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>deaf</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.284016</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.026208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>trans</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.229855</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.080369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sikh</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.356671</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.046447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>elderly</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.355350</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.045126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>american</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.412814</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.102590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>hispanic</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.233818</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.076406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>old</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.357992</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.047768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>christian</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.342140</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.031916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>mexican</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.350066</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.039842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>blind</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.233818</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.076406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>latinx</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.357992</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.047768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>young</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.335535</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.025311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>asian</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.233818</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.076406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>white</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.229855</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.080369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>homosexual</td>\n",
       "      <td>0.326288</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.317302</td>\n",
       "      <td>0.310224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>nonbinary</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.357992</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.047768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>japanese</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.363276</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.053052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>teenage</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.287979</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.022245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>millenial</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.365918</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.055694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>gay</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.357992</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.047768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>protestant</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.298547</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.011677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>chinese</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.351387</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.041163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>latina</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.294584</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.015640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>taoist</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.357992</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.047768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>queer</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.117569</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.192655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>heterosexual</td>\n",
       "      <td>0.128137</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.014531</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.119151</td>\n",
       "      <td>0.295693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>catholic</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.365918</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.055694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>older</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.414795</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.104571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>paralyzed</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.357992</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.047768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Identity_Titles  Identity_Term_False_Positive  Total_False_Positive  \\\n",
       "0         buddhist                      0.000000              0.008986   \n",
       "1         canadian                      0.000000              0.008986   \n",
       "2             male                      0.000000              0.008986   \n",
       "3      transgender                      0.000000              0.008986   \n",
       "4          african                      0.000000              0.008986   \n",
       "5            black                      0.000000              0.008986   \n",
       "6            lgbtq                      0.000000              0.008986   \n",
       "7           female                      0.000000              0.008986   \n",
       "8         bisexual                      0.000000              0.008986   \n",
       "9           latino                      0.000000              0.008986   \n",
       "10        straight                      0.000000              0.008986   \n",
       "11            lgbt                      0.000000              0.008986   \n",
       "12          indian                      0.000000              0.008986   \n",
       "13         lesbian                      0.000000              0.008986   \n",
       "14          jewish                      0.000000              0.008986   \n",
       "15          muslim                      0.000000              0.008986   \n",
       "16        european                      0.000000              0.008986   \n",
       "17         younger                      0.000000              0.008986   \n",
       "18            deaf                      0.000000              0.008986   \n",
       "19           trans                      0.000000              0.008986   \n",
       "20            sikh                      0.000000              0.008986   \n",
       "21         elderly                      0.000000              0.008986   \n",
       "22        american                      0.000000              0.008986   \n",
       "23        hispanic                      0.000000              0.008986   \n",
       "24             old                      0.000000              0.008986   \n",
       "25       christian                      0.000000              0.008986   \n",
       "26         mexican                      0.000000              0.008986   \n",
       "27           blind                      0.000000              0.008986   \n",
       "28          latinx                      0.000000              0.008986   \n",
       "29           young                      0.000000              0.008986   \n",
       "30           asian                      0.000000              0.008986   \n",
       "31           white                      0.000000              0.008986   \n",
       "32      homosexual                      0.326288              0.008986   \n",
       "33       nonbinary                      0.000000              0.008986   \n",
       "34        japanese                      0.000000              0.008986   \n",
       "35         teenage                      0.000000              0.008986   \n",
       "36       millenial                      0.000000              0.008986   \n",
       "37             gay                      0.000000              0.008986   \n",
       "38      protestant                      0.000000              0.008986   \n",
       "39         chinese                      0.000000              0.008986   \n",
       "40          latina                      0.000000              0.008986   \n",
       "41          taoist                      0.000000              0.008986   \n",
       "42           queer                      0.000000              0.008986   \n",
       "43    heterosexual                      0.128137              0.008986   \n",
       "44        catholic                      0.000000              0.008986   \n",
       "45           older                      0.000000              0.008986   \n",
       "46       paralyzed                      0.000000              0.008986   \n",
       "\n",
       "    Identity_Term_False_Negatives  Total_False_Negative  FPR - FPRt  \\\n",
       "0                        0.354029              0.310224    0.008986   \n",
       "1                        0.463672              0.310224    0.008986   \n",
       "2                        0.221929              0.310224    0.008986   \n",
       "3                        0.297226              0.310224    0.008986   \n",
       "4                        0.357992              0.310224    0.008986   \n",
       "5                        0.212682              0.310224    0.008986   \n",
       "6                        0.400264              0.310224    0.008986   \n",
       "7                        0.286658              0.310224    0.008986   \n",
       "8                        0.116248              0.310224    0.008986   \n",
       "9                        0.174373              0.310224    0.008986   \n",
       "10                       0.232497              0.310224    0.008986   \n",
       "11                       0.417437              0.310224    0.008986   \n",
       "12                       0.414795              0.310224    0.008986   \n",
       "13                       0.110964              0.310224    0.008986   \n",
       "14                       0.336856              0.310224    0.008986   \n",
       "15                       0.346103              0.310224    0.008986   \n",
       "16                       0.368560              0.310224    0.008986   \n",
       "17                       0.414795              0.310224    0.008986   \n",
       "18                       0.284016              0.310224    0.008986   \n",
       "19                       0.229855              0.310224    0.008986   \n",
       "20                       0.356671              0.310224    0.008986   \n",
       "21                       0.355350              0.310224    0.008986   \n",
       "22                       0.412814              0.310224    0.008986   \n",
       "23                       0.233818              0.310224    0.008986   \n",
       "24                       0.357992              0.310224    0.008986   \n",
       "25                       0.342140              0.310224    0.008986   \n",
       "26                       0.350066              0.310224    0.008986   \n",
       "27                       0.233818              0.310224    0.008986   \n",
       "28                       0.357992              0.310224    0.008986   \n",
       "29                       0.335535              0.310224    0.008986   \n",
       "30                       0.233818              0.310224    0.008986   \n",
       "31                       0.229855              0.310224    0.008986   \n",
       "32                       0.000000              0.310224    0.317302   \n",
       "33                       0.357992              0.310224    0.008986   \n",
       "34                       0.363276              0.310224    0.008986   \n",
       "35                       0.287979              0.310224    0.008986   \n",
       "36                       0.365918              0.310224    0.008986   \n",
       "37                       0.357992              0.310224    0.008986   \n",
       "38                       0.298547              0.310224    0.008986   \n",
       "39                       0.351387              0.310224    0.008986   \n",
       "40                       0.294584              0.310224    0.008986   \n",
       "41                       0.357992              0.310224    0.008986   \n",
       "42                       0.117569              0.310224    0.008986   \n",
       "43                       0.014531              0.310224    0.119151   \n",
       "44                       0.365918              0.310224    0.008986   \n",
       "45                       0.414795              0.310224    0.008986   \n",
       "46                       0.357992              0.310224    0.008986   \n",
       "\n",
       "    FNR - FNRt  \n",
       "0     0.043805  \n",
       "1     0.153448  \n",
       "2     0.088295  \n",
       "3     0.012998  \n",
       "4     0.047768  \n",
       "5     0.097542  \n",
       "6     0.090040  \n",
       "7     0.023566  \n",
       "8     0.193976  \n",
       "9     0.135852  \n",
       "10    0.077727  \n",
       "11    0.107213  \n",
       "12    0.104571  \n",
       "13    0.199260  \n",
       "14    0.026632  \n",
       "15    0.035879  \n",
       "16    0.058336  \n",
       "17    0.104571  \n",
       "18    0.026208  \n",
       "19    0.080369  \n",
       "20    0.046447  \n",
       "21    0.045126  \n",
       "22    0.102590  \n",
       "23    0.076406  \n",
       "24    0.047768  \n",
       "25    0.031916  \n",
       "26    0.039842  \n",
       "27    0.076406  \n",
       "28    0.047768  \n",
       "29    0.025311  \n",
       "30    0.076406  \n",
       "31    0.080369  \n",
       "32    0.310224  \n",
       "33    0.047768  \n",
       "34    0.053052  \n",
       "35    0.022245  \n",
       "36    0.055694  \n",
       "37    0.047768  \n",
       "38    0.011677  \n",
       "39    0.041163  \n",
       "40    0.015640  \n",
       "41    0.047768  \n",
       "42    0.192655  \n",
       "43    0.295693  \n",
       "44    0.055694  \n",
       "45    0.104571  \n",
       "46    0.047768  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def perf_measure(y_actual, y_hat):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(y_hat)): \n",
    "        if y_actual[i]==y_hat[i]==1:\n",
    "           TP += 1\n",
    "        if y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n",
    "           FP += 1\n",
    "        if y_actual[i]==y_hat[i]==0:\n",
    "           TN += 1\n",
    "        if y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n",
    "           FN += 1\n",
    "\n",
    "    return(TN, FP, FN, TP)\n",
    "\n",
    "\n",
    "\n",
    "total_tn, total_fp, total_fn, total_tp = confusion_matrix(test_labels, pred.round()).ravel()\n",
    "total_fpr = total_fp / (total_fp + total_tn )\n",
    "total_fnr = total_fn / (total_fn + total_tp)\n",
    "false_positive = []\n",
    "false_negative = []\n",
    "identity_terms = []\n",
    "for identity_term in set(terms):\n",
    "    data = df_test[df_test['Identity_Terms'] == identity_term].reset_index()\n",
    "    y_true, y_pred = data['Label'].astype(int), data['prediction_scores']\n",
    "    tn, fp, fn, tp = perf_measure(y_true, y_pred.round())\n",
    "    try:\n",
    "        fpr = fp / (fp + tn)\n",
    "        fnr = fn / (fn + tp)\n",
    "        false_positive.append(fpr)\n",
    "        false_negative.append(fnr)\n",
    "        identity_terms.append(identity_term)\n",
    "    except:\n",
    "        print(\"Error in \", identity_term)\n",
    "\n",
    "    \n",
    "eval_scores = pd.DataFrame(identity_terms, columns = ['Identity_Titles'])\n",
    "eval_scores['Identity_Term_False_Positive'] = false_positive\n",
    "eval_scores['Total_False_Positive'] = total_fpr\n",
    "eval_scores['Identity_Term_False_Negatives'] = false_negative\n",
    "eval_scores['Total_False_Negative'] = total_fnr\n",
    "eval_scores['FPR - FPRt'] = abs(total_fpr - eval_scores['Identity_Term_False_Positive'])\n",
    "eval_scores['FNR - FNRt'] = abs(total_fnr - eval_scores['Identity_Term_False_Negatives'])\n",
    "eval_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8408210583808386, 3.7537943925414248)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_scores['FPR - FPRt'].sum(), eval_scores['FNR - FNRt'].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in  nan\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Identity_Titles</th>\n",
       "      <th>AUCt</th>\n",
       "      <th>AUC</th>\n",
       "      <th>AUC - AUCt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>buddhist</td>\n",
       "      <td>0.826770</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.013625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>canadian</td>\n",
       "      <td>0.799805</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.040590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>0.859259</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.018864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>transgender</td>\n",
       "      <td>0.840740</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.000345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>african</td>\n",
       "      <td>0.825795</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.014599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>black</td>\n",
       "      <td>0.861533</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.021138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lgbtq</td>\n",
       "      <td>0.815399</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.024996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>female</td>\n",
       "      <td>0.843339</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.002944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bisexual</td>\n",
       "      <td>0.885250</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.044855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>latino</td>\n",
       "      <td>0.870955</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.030560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>straight</td>\n",
       "      <td>0.856660</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.016265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>lgbt</td>\n",
       "      <td>0.811176</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.029219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>indian</td>\n",
       "      <td>0.811825</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.028570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lesbian</td>\n",
       "      <td>0.886549</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.046154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>jewish</td>\n",
       "      <td>0.830994</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.009401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>muslim</td>\n",
       "      <td>0.828719</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.011675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>european</td>\n",
       "      <td>0.823196</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.017199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>younger</td>\n",
       "      <td>0.811825</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.028570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>deaf</td>\n",
       "      <td>0.843989</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.003594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>trans</td>\n",
       "      <td>0.857309</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.016914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sikh</td>\n",
       "      <td>0.826120</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.014275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>elderly</td>\n",
       "      <td>0.826445</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.013950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>american</td>\n",
       "      <td>0.815523</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.024872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>hispanic</td>\n",
       "      <td>0.856335</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.015940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>old</td>\n",
       "      <td>0.825795</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.014599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>christian</td>\n",
       "      <td>0.829694</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.010701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>mexican</td>\n",
       "      <td>0.827745</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.012650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>blind</td>\n",
       "      <td>0.856335</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.015940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>latinx</td>\n",
       "      <td>0.825795</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.014599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>young</td>\n",
       "      <td>0.831319</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.009076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>asian</td>\n",
       "      <td>0.856335</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.015940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>white</td>\n",
       "      <td>0.857309</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.016914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>homosexual</td>\n",
       "      <td>0.830898</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.009497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>nonbinary</td>\n",
       "      <td>0.825795</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.014599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>japanese</td>\n",
       "      <td>0.824496</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.015899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>teenage</td>\n",
       "      <td>0.843014</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.002620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>millenial</td>\n",
       "      <td>0.823846</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.016549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>gay</td>\n",
       "      <td>0.825795</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.014599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>protestant</td>\n",
       "      <td>0.840415</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>chinese</td>\n",
       "      <td>0.827420</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.012975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>latina</td>\n",
       "      <td>0.841390</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.000995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>taoist</td>\n",
       "      <td>0.825795</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.014599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>queer</td>\n",
       "      <td>0.884925</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.044530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>heterosexual</td>\n",
       "      <td>0.877694</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.037299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>catholic</td>\n",
       "      <td>0.823846</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.016549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>older</td>\n",
       "      <td>0.811825</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.028570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>paralyzed</td>\n",
       "      <td>0.825795</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.014599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Identity_Titles      AUCt       AUC  AUC - AUCt\n",
       "0         buddhist  0.826770  0.840395    0.013625\n",
       "1         canadian  0.799805  0.840395    0.040590\n",
       "2             male  0.859259  0.840395    0.018864\n",
       "3      transgender  0.840740  0.840395    0.000345\n",
       "4          african  0.825795  0.840395    0.014599\n",
       "5            black  0.861533  0.840395    0.021138\n",
       "6            lgbtq  0.815399  0.840395    0.024996\n",
       "7           female  0.843339  0.840395    0.002944\n",
       "8         bisexual  0.885250  0.840395    0.044855\n",
       "9           latino  0.870955  0.840395    0.030560\n",
       "10        straight  0.856660  0.840395    0.016265\n",
       "11            lgbt  0.811176  0.840395    0.029219\n",
       "12          indian  0.811825  0.840395    0.028570\n",
       "13         lesbian  0.886549  0.840395    0.046154\n",
       "14          jewish  0.830994  0.840395    0.009401\n",
       "15          muslim  0.828719  0.840395    0.011675\n",
       "16        european  0.823196  0.840395    0.017199\n",
       "17         younger  0.811825  0.840395    0.028570\n",
       "18            deaf  0.843989  0.840395    0.003594\n",
       "19           trans  0.857309  0.840395    0.016914\n",
       "20            sikh  0.826120  0.840395    0.014275\n",
       "21         elderly  0.826445  0.840395    0.013950\n",
       "22        american  0.815523  0.840395    0.024872\n",
       "23        hispanic  0.856335  0.840395    0.015940\n",
       "24             old  0.825795  0.840395    0.014599\n",
       "25       christian  0.829694  0.840395    0.010701\n",
       "26         mexican  0.827745  0.840395    0.012650\n",
       "27           blind  0.856335  0.840395    0.015940\n",
       "28          latinx  0.825795  0.840395    0.014599\n",
       "29           young  0.831319  0.840395    0.009076\n",
       "30           asian  0.856335  0.840395    0.015940\n",
       "31           white  0.857309  0.840395    0.016914\n",
       "32      homosexual  0.830898  0.840395    0.009497\n",
       "33       nonbinary  0.825795  0.840395    0.014599\n",
       "34        japanese  0.824496  0.840395    0.015899\n",
       "35         teenage  0.843014  0.840395    0.002620\n",
       "36       millenial  0.823846  0.840395    0.016549\n",
       "37             gay  0.825795  0.840395    0.014599\n",
       "38      protestant  0.840415  0.840395    0.000020\n",
       "39         chinese  0.827420  0.840395    0.012975\n",
       "40          latina  0.841390  0.840395    0.000995\n",
       "41          taoist  0.825795  0.840395    0.014599\n",
       "42           queer  0.884925  0.840395    0.044530\n",
       "43    heterosexual  0.877694  0.840395    0.037299\n",
       "44        catholic  0.823846  0.840395    0.016549\n",
       "45           older  0.811825  0.840395    0.028570\n",
       "46       paralyzed  0.825795  0.840395    0.014599"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_auc = roc_auc_score(test_labels, pred.round())\n",
    "terms_auc = []\n",
    "identity_terms = []\n",
    "for identity_term in set(terms):\n",
    "    term_data = df_test[df_test['Identity_Terms'] == identity_term].reset_index()\n",
    "    data = df_test.sample(n=len(term_data['Text']), random_state=0)\n",
    "    data = term_data.append(data, ignore_index=True)\n",
    "    y_true, y_pred = data['Label'].astype(int), data['prediction_scores']\n",
    "\n",
    "    try:\n",
    "        term_auc = roc_auc_score(y_true, y_pred.round())\n",
    "        terms_auc.append(term_auc)\n",
    "        identity_terms.append(identity_term)\n",
    "    except:\n",
    "        print(\"Error in \",identity_term)\n",
    "\n",
    "\n",
    "    \n",
    "eval_scores = pd.DataFrame(identity_terms, columns = ['Identity_Titles'])\n",
    "eval_scores['AUCt'] = terms_auc\n",
    "eval_scores['AUC'] = total_auc\n",
    "eval_scores['AUC - AUCt'] = abs(eval_scores['AUC'] - eval_scores['AUCt'])\n",
    "eval_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8434344934908964\n"
     ]
    }
   ],
   "source": [
    "print(eval_scores['AUC - AUCt'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "theta = 0.55\n",
    "features = []\n",
    "labels = []\n",
    "for i in tqdm_notebook(range(len(test_features[:]))):\n",
    "    p_positive = pred[i]\n",
    "    p_negative = 1 - p_positive\n",
    "    feature = test_features[i]\n",
    "    label = df_test.loc[i, 'Label']\n",
    "    #feature = [np.hstack((feature, label))]\n",
    "    if max(p_positive, p_negative) < theta:\n",
    "        features.append(feature)\n",
    "        labels.append(label)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNN = KNeighborsClassifier(n_neighbors=3, weights = 'distance',n_jobs = -1)\n",
    "KNN.fit(features, labels)\n",
    "\n",
    "SM_pred = []\n",
    "indices = []\n",
    "for i in tqdm_notebook(range(len(test_features[:]))):\n",
    "    p_positive = pred[i]\n",
    "    p_negative = 1 - p_positive\n",
    "    feature = [test_features[i]]\n",
    "    label = df_test.loc[i, 'Label']\n",
    "    #feature = [np.hstack((feature, label))]\n",
    "    if max(p_positive, p_negative) < theta:\n",
    "        prediction = KNN.predict(feature)\n",
    "        SM_pred.append(int(prediction))\n",
    "    else:\n",
    "        SM_pred.append(int(p_positive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f290ca53934d4a239f19e9dc01c12b5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=76564.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "theta = 0.8\n",
    "ROC_pred = []\n",
    "for i in tqdm_notebook(range(len(test_features))):\n",
    "    p_positive = pred[i]\n",
    "    p_negative = 1 - p_positive\n",
    "    deprived_term = list(set(test_feature[i]).intersection(set(terms)))\n",
    "    if max(p_positive, p_negative) < theta and len(deprived_term) > 0:\n",
    "        #print(i, deprived_term, favoured_term)\n",
    "        ROC_pred.append(0)\n",
    "    elif max(p_positive, p_negative) < theta and len(deprived_term) == 0 :\n",
    "        ROC_pred.append(1)\n",
    "        \n",
    "    else:\n",
    "        ROC_pred.append(int(pred[i].round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2acad3d0797c47778609486a5c35ae87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=76564.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "xf_positive = 0\n",
    "xd_positive = 0\n",
    "xf_total = 0\n",
    "xd_total = 0\n",
    "\n",
    "for i in tqdm_notebook(range(len(test_feature))):\n",
    "    if(ROC_pred[i] == 1 and len(list(set(test_feature[i]).intersection(set(terms)))) > 0):\n",
    "        xd_positive += 1\n",
    "        xd_total += 1\n",
    "    elif(len(list(set(test_feature[i]).intersection(set(terms)))) > 0):\n",
    "        xd_total += 1\n",
    "    elif(ROC_pred[i] == 1 and len(list(set(test_feature[i]).intersection(set(terms))))== 0):\n",
    "        xf_positive += 1\n",
    "        xf_total += 1\n",
    "    elif(len(list(set(test_feature[i]).intersection(set(terms))))== 0):\n",
    "        xf_total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27239507579920075"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf = xf_positive / xf_total\n",
    "pd = xd_positive / xd_total\n",
    "discrimination = pf - pd\n",
    "discrimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6974296013792383"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_labels, ROC_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in  nan\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Identity_Titles</th>\n",
       "      <th>Identity_Term_False_Positive</th>\n",
       "      <th>Total_False_Positive</th>\n",
       "      <th>Identity_Term_False_Negatives</th>\n",
       "      <th>Total_False_Negative</th>\n",
       "      <th>FPR - FPRt</th>\n",
       "      <th>FNR - FNRt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>buddhist</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.354029</td>\n",
       "      <td>0.605115</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.251086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>canadian</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.463672</td>\n",
       "      <td>0.605115</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.141442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.221929</td>\n",
       "      <td>0.605115</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.383186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>transgender</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.297226</td>\n",
       "      <td>0.605115</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.307889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>african</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.357992</td>\n",
       "      <td>0.605115</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.247123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>black</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.212682</td>\n",
       "      <td>0.605115</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.392433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lgbtq</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.400264</td>\n",
       "      <td>0.605115</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.204850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>female</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.286658</td>\n",
       "      <td>0.605115</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.318457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bisexual</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.116248</td>\n",
       "      <td>0.605115</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.488866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>latino</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.174373</td>\n",
       "      <td>0.605115</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.430742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>straight</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.232497</td>\n",
       "      <td>0.605115</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.372618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>lgbt</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.417437</td>\n",
       "      <td>0.605115</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.187677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>indian</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.414795</td>\n",
       "      <td>0.605115</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.190319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lesbian</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.110964</td>\n",
       "      <td>0.605115</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.494150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>jewish</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.336856</td>\n",
       "      <td>0.605115</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.268259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>muslim</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.346103</td>\n",
       "      <td>0.605115</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.259012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>european</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.368560</td>\n",
       "      <td>0.605115</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.236555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>younger</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.414795</td>\n",
       "      <td>0.605115</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.190319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>deaf</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.284016</td>\n",
       "      <td>0.605115</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.321099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>trans</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.229855</td>\n",
       "      <td>0.605115</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.375260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sikh</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.356671</td>\n",
       "      <td>0.605115</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.248444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>elderly</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.355350</td>\n",
       "      <td>0.605115</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.249765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>american</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.412814</td>\n",
       "      <td>0.605115</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.192301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>hispanic</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.233818</td>\n",
       "      <td>0.605115</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.371297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>old</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.357992</td>\n",
       "      <td>0.605115</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.247123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>christian</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.342140</td>\n",
       "      <td>0.605115</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.262975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>mexican</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.350066</td>\n",
       "      <td>0.605115</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.255049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>blind</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.233818</td>\n",
       "      <td>0.605115</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.371297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>latinx</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.357992</td>\n",
       "      <td>0.605115</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.247123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>young</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.335535</td>\n",
       "      <td>0.605115</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.269580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>asian</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.233818</td>\n",
       "      <td>0.605115</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.371297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>white</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.229855</td>\n",
       "      <td>0.605115</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.375260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>homosexual</td>\n",
       "      <td>0.326288</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.605115</td>\n",
       "      <td>0.326262</td>\n",
       "      <td>0.605115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>nonbinary</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.357992</td>\n",
       "      <td>0.605115</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.247123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>japanese</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.363276</td>\n",
       "      <td>0.605115</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.241839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>teenage</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.287979</td>\n",
       "      <td>0.605115</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.317136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>millenial</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.365918</td>\n",
       "      <td>0.605115</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.239197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>gay</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.357992</td>\n",
       "      <td>0.605115</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.247123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>protestant</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.298547</td>\n",
       "      <td>0.605115</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.306568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>chinese</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.351387</td>\n",
       "      <td>0.605115</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.253728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>latina</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.294584</td>\n",
       "      <td>0.605115</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.310531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>taoist</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.357992</td>\n",
       "      <td>0.605115</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.247123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>queer</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.117569</td>\n",
       "      <td>0.605115</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.487545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>heterosexual</td>\n",
       "      <td>0.128137</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.014531</td>\n",
       "      <td>0.605115</td>\n",
       "      <td>0.128111</td>\n",
       "      <td>0.590584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>catholic</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.365918</td>\n",
       "      <td>0.605115</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.239197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>older</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.414795</td>\n",
       "      <td>0.605115</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.190319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>paralyzed</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.357992</td>\n",
       "      <td>0.605115</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.247123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Identity_Titles  Identity_Term_False_Positive  Total_False_Positive  \\\n",
       "0         buddhist                      0.000000              0.000026   \n",
       "1         canadian                      0.000000              0.000026   \n",
       "2             male                      0.000000              0.000026   \n",
       "3      transgender                      0.000000              0.000026   \n",
       "4          african                      0.000000              0.000026   \n",
       "5            black                      0.000000              0.000026   \n",
       "6            lgbtq                      0.000000              0.000026   \n",
       "7           female                      0.000000              0.000026   \n",
       "8         bisexual                      0.000000              0.000026   \n",
       "9           latino                      0.000000              0.000026   \n",
       "10        straight                      0.000000              0.000026   \n",
       "11            lgbt                      0.000000              0.000026   \n",
       "12          indian                      0.000000              0.000026   \n",
       "13         lesbian                      0.000000              0.000026   \n",
       "14          jewish                      0.000000              0.000026   \n",
       "15          muslim                      0.000000              0.000026   \n",
       "16        european                      0.000000              0.000026   \n",
       "17         younger                      0.000000              0.000026   \n",
       "18            deaf                      0.000000              0.000026   \n",
       "19           trans                      0.000000              0.000026   \n",
       "20            sikh                      0.000000              0.000026   \n",
       "21         elderly                      0.000000              0.000026   \n",
       "22        american                      0.000000              0.000026   \n",
       "23        hispanic                      0.000000              0.000026   \n",
       "24             old                      0.000000              0.000026   \n",
       "25       christian                      0.000000              0.000026   \n",
       "26         mexican                      0.000000              0.000026   \n",
       "27           blind                      0.000000              0.000026   \n",
       "28          latinx                      0.000000              0.000026   \n",
       "29           young                      0.000000              0.000026   \n",
       "30           asian                      0.000000              0.000026   \n",
       "31           white                      0.000000              0.000026   \n",
       "32      homosexual                      0.326288              0.000026   \n",
       "33       nonbinary                      0.000000              0.000026   \n",
       "34        japanese                      0.000000              0.000026   \n",
       "35         teenage                      0.000000              0.000026   \n",
       "36       millenial                      0.000000              0.000026   \n",
       "37             gay                      0.000000              0.000026   \n",
       "38      protestant                      0.000000              0.000026   \n",
       "39         chinese                      0.000000              0.000026   \n",
       "40          latina                      0.000000              0.000026   \n",
       "41          taoist                      0.000000              0.000026   \n",
       "42           queer                      0.000000              0.000026   \n",
       "43    heterosexual                      0.128137              0.000026   \n",
       "44        catholic                      0.000000              0.000026   \n",
       "45           older                      0.000000              0.000026   \n",
       "46       paralyzed                      0.000000              0.000026   \n",
       "\n",
       "    Identity_Term_False_Negatives  Total_False_Negative  FPR - FPRt  \\\n",
       "0                        0.354029              0.605115    0.000026   \n",
       "1                        0.463672              0.605115    0.000026   \n",
       "2                        0.221929              0.605115    0.000026   \n",
       "3                        0.297226              0.605115    0.000026   \n",
       "4                        0.357992              0.605115    0.000026   \n",
       "5                        0.212682              0.605115    0.000026   \n",
       "6                        0.400264              0.605115    0.000026   \n",
       "7                        0.286658              0.605115    0.000026   \n",
       "8                        0.116248              0.605115    0.000026   \n",
       "9                        0.174373              0.605115    0.000026   \n",
       "10                       0.232497              0.605115    0.000026   \n",
       "11                       0.417437              0.605115    0.000026   \n",
       "12                       0.414795              0.605115    0.000026   \n",
       "13                       0.110964              0.605115    0.000026   \n",
       "14                       0.336856              0.605115    0.000026   \n",
       "15                       0.346103              0.605115    0.000026   \n",
       "16                       0.368560              0.605115    0.000026   \n",
       "17                       0.414795              0.605115    0.000026   \n",
       "18                       0.284016              0.605115    0.000026   \n",
       "19                       0.229855              0.605115    0.000026   \n",
       "20                       0.356671              0.605115    0.000026   \n",
       "21                       0.355350              0.605115    0.000026   \n",
       "22                       0.412814              0.605115    0.000026   \n",
       "23                       0.233818              0.605115    0.000026   \n",
       "24                       0.357992              0.605115    0.000026   \n",
       "25                       0.342140              0.605115    0.000026   \n",
       "26                       0.350066              0.605115    0.000026   \n",
       "27                       0.233818              0.605115    0.000026   \n",
       "28                       0.357992              0.605115    0.000026   \n",
       "29                       0.335535              0.605115    0.000026   \n",
       "30                       0.233818              0.605115    0.000026   \n",
       "31                       0.229855              0.605115    0.000026   \n",
       "32                       0.000000              0.605115    0.326262   \n",
       "33                       0.357992              0.605115    0.000026   \n",
       "34                       0.363276              0.605115    0.000026   \n",
       "35                       0.287979              0.605115    0.000026   \n",
       "36                       0.365918              0.605115    0.000026   \n",
       "37                       0.357992              0.605115    0.000026   \n",
       "38                       0.298547              0.605115    0.000026   \n",
       "39                       0.351387              0.605115    0.000026   \n",
       "40                       0.294584              0.605115    0.000026   \n",
       "41                       0.357992              0.605115    0.000026   \n",
       "42                       0.117569              0.605115    0.000026   \n",
       "43                       0.014531              0.605115    0.128111   \n",
       "44                       0.365918              0.605115    0.000026   \n",
       "45                       0.414795              0.605115    0.000026   \n",
       "46                       0.357992              0.605115    0.000026   \n",
       "\n",
       "    FNR - FNRt  \n",
       "0     0.251086  \n",
       "1     0.141442  \n",
       "2     0.383186  \n",
       "3     0.307889  \n",
       "4     0.247123  \n",
       "5     0.392433  \n",
       "6     0.204850  \n",
       "7     0.318457  \n",
       "8     0.488866  \n",
       "9     0.430742  \n",
       "10    0.372618  \n",
       "11    0.187677  \n",
       "12    0.190319  \n",
       "13    0.494150  \n",
       "14    0.268259  \n",
       "15    0.259012  \n",
       "16    0.236555  \n",
       "17    0.190319  \n",
       "18    0.321099  \n",
       "19    0.375260  \n",
       "20    0.248444  \n",
       "21    0.249765  \n",
       "22    0.192301  \n",
       "23    0.371297  \n",
       "24    0.247123  \n",
       "25    0.262975  \n",
       "26    0.255049  \n",
       "27    0.371297  \n",
       "28    0.247123  \n",
       "29    0.269580  \n",
       "30    0.371297  \n",
       "31    0.375260  \n",
       "32    0.605115  \n",
       "33    0.247123  \n",
       "34    0.241839  \n",
       "35    0.317136  \n",
       "36    0.239197  \n",
       "37    0.247123  \n",
       "38    0.306568  \n",
       "39    0.253728  \n",
       "40    0.310531  \n",
       "41    0.247123  \n",
       "42    0.487545  \n",
       "43    0.590584  \n",
       "44    0.239197  \n",
       "45    0.190319  \n",
       "46    0.247123  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_data['prediction_scores'] = ROC_pred\n",
    "import pandas as pd\n",
    "total_tn, total_fp, total_fn, total_tp = confusion_matrix(test_labels, ROC_pred).ravel()\n",
    "total_fpr = total_fp / (total_fp + total_tn )\n",
    "total_fnr = total_fn / (total_fn + total_tp)\n",
    "false_positive = []\n",
    "false_negative = []\n",
    "identity_terms = []\n",
    "for identity_term in set(terms):\n",
    "    data = df_test[df_test['Identity_Terms'] == identity_term].reset_index()\n",
    "    y_true, y_pred = data['Label'].astype(int), data['prediction_scores']\n",
    "    tn, fp, fn, tp = perf_measure(y_true, y_pred.round())\n",
    "    try:\n",
    "        fpr = fp / (fp + tn)\n",
    "        fnr = fn / (fn + tp)\n",
    "        false_positive.append(fpr)\n",
    "        false_negative.append(fnr)\n",
    "        identity_terms.append(identity_term)\n",
    "    except:\n",
    "        print(\"Error in \", identity_term)\n",
    "\n",
    "    \n",
    "eval_scores = pd.DataFrame(identity_terms, columns = ['Identity_Titles'])\n",
    "eval_scores['Identity_Term_False_Positive'] = false_positive\n",
    "eval_scores['Total_False_Positive'] = total_fpr\n",
    "eval_scores['Identity_Term_False_Negatives'] = false_negative\n",
    "eval_scores['Total_False_Negative'] = total_fnr\n",
    "eval_scores['FPR - FPRt'] = abs(total_fpr - eval_scores['Identity_Term_False_Positive'])\n",
    "eval_scores['FNR - FNRt'] = abs(total_fnr - eval_scores['Identity_Term_False_Negatives'])\n",
    "eval_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.45554860657581286, 14.293097797427246)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_scores['FPR - FPRt'].sum(), eval_scores['FNR - FNRt'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in  nan\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Identity_Titles</th>\n",
       "      <th>AUCt</th>\n",
       "      <th>AUC</th>\n",
       "      <th>AUC - AUCt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>buddhist</td>\n",
       "      <td>0.826770</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>0.129341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>canadian</td>\n",
       "      <td>0.799805</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>0.102375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>0.859259</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>0.161829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>transgender</td>\n",
       "      <td>0.840740</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>0.143311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>african</td>\n",
       "      <td>0.825795</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>0.128366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>black</td>\n",
       "      <td>0.861533</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>0.164103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lgbtq</td>\n",
       "      <td>0.815399</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>0.117970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>female</td>\n",
       "      <td>0.843339</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>0.145910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bisexual</td>\n",
       "      <td>0.885250</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>0.187820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>latino</td>\n",
       "      <td>0.870955</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>0.173525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>straight</td>\n",
       "      <td>0.856660</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>0.159230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>lgbt</td>\n",
       "      <td>0.811176</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>0.113746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>indian</td>\n",
       "      <td>0.811825</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>0.114396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lesbian</td>\n",
       "      <td>0.886549</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>0.189120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>jewish</td>\n",
       "      <td>0.830994</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>0.133564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>muslim</td>\n",
       "      <td>0.828719</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>0.131290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>european</td>\n",
       "      <td>0.823196</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>0.125767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>younger</td>\n",
       "      <td>0.811825</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>0.114396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>deaf</td>\n",
       "      <td>0.843989</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>0.146560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>trans</td>\n",
       "      <td>0.857309</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>0.159880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sikh</td>\n",
       "      <td>0.826120</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>0.128691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>elderly</td>\n",
       "      <td>0.826445</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>0.129016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>american</td>\n",
       "      <td>0.815523</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>0.118093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>hispanic</td>\n",
       "      <td>0.856335</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>0.158905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>old</td>\n",
       "      <td>0.825795</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>0.128366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>christian</td>\n",
       "      <td>0.829694</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>0.132265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>mexican</td>\n",
       "      <td>0.827745</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>0.130315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>blind</td>\n",
       "      <td>0.856335</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>0.158905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>latinx</td>\n",
       "      <td>0.825795</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>0.128366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>young</td>\n",
       "      <td>0.831319</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>0.133889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>asian</td>\n",
       "      <td>0.856335</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>0.158905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>white</td>\n",
       "      <td>0.857309</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>0.159880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>homosexual</td>\n",
       "      <td>0.830898</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>0.133469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>nonbinary</td>\n",
       "      <td>0.825795</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>0.128366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>japanese</td>\n",
       "      <td>0.824496</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>0.127066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>teenage</td>\n",
       "      <td>0.843014</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>0.145585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>millenial</td>\n",
       "      <td>0.823846</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>0.126417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>gay</td>\n",
       "      <td>0.825795</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>0.128366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>protestant</td>\n",
       "      <td>0.840415</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>0.142986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>chinese</td>\n",
       "      <td>0.827420</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>0.129990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>latina</td>\n",
       "      <td>0.841390</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>0.143960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>taoist</td>\n",
       "      <td>0.825795</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>0.128366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>queer</td>\n",
       "      <td>0.884925</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>0.187495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>heterosexual</td>\n",
       "      <td>0.877694</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>0.180264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>catholic</td>\n",
       "      <td>0.823846</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>0.126417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>older</td>\n",
       "      <td>0.811825</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>0.114396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>paralyzed</td>\n",
       "      <td>0.825795</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>0.128366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Identity_Titles      AUCt      AUC  AUC - AUCt\n",
       "0         buddhist  0.826770  0.69743    0.129341\n",
       "1         canadian  0.799805  0.69743    0.102375\n",
       "2             male  0.859259  0.69743    0.161829\n",
       "3      transgender  0.840740  0.69743    0.143311\n",
       "4          african  0.825795  0.69743    0.128366\n",
       "5            black  0.861533  0.69743    0.164103\n",
       "6            lgbtq  0.815399  0.69743    0.117970\n",
       "7           female  0.843339  0.69743    0.145910\n",
       "8         bisexual  0.885250  0.69743    0.187820\n",
       "9           latino  0.870955  0.69743    0.173525\n",
       "10        straight  0.856660  0.69743    0.159230\n",
       "11            lgbt  0.811176  0.69743    0.113746\n",
       "12          indian  0.811825  0.69743    0.114396\n",
       "13         lesbian  0.886549  0.69743    0.189120\n",
       "14          jewish  0.830994  0.69743    0.133564\n",
       "15          muslim  0.828719  0.69743    0.131290\n",
       "16        european  0.823196  0.69743    0.125767\n",
       "17         younger  0.811825  0.69743    0.114396\n",
       "18            deaf  0.843989  0.69743    0.146560\n",
       "19           trans  0.857309  0.69743    0.159880\n",
       "20            sikh  0.826120  0.69743    0.128691\n",
       "21         elderly  0.826445  0.69743    0.129016\n",
       "22        american  0.815523  0.69743    0.118093\n",
       "23        hispanic  0.856335  0.69743    0.158905\n",
       "24             old  0.825795  0.69743    0.128366\n",
       "25       christian  0.829694  0.69743    0.132265\n",
       "26         mexican  0.827745  0.69743    0.130315\n",
       "27           blind  0.856335  0.69743    0.158905\n",
       "28          latinx  0.825795  0.69743    0.128366\n",
       "29           young  0.831319  0.69743    0.133889\n",
       "30           asian  0.856335  0.69743    0.158905\n",
       "31           white  0.857309  0.69743    0.159880\n",
       "32      homosexual  0.830898  0.69743    0.133469\n",
       "33       nonbinary  0.825795  0.69743    0.128366\n",
       "34        japanese  0.824496  0.69743    0.127066\n",
       "35         teenage  0.843014  0.69743    0.145585\n",
       "36       millenial  0.823846  0.69743    0.126417\n",
       "37             gay  0.825795  0.69743    0.128366\n",
       "38      protestant  0.840415  0.69743    0.142986\n",
       "39         chinese  0.827420  0.69743    0.129990\n",
       "40          latina  0.841390  0.69743    0.143960\n",
       "41          taoist  0.825795  0.69743    0.128366\n",
       "42           queer  0.884925  0.69743    0.187495\n",
       "43    heterosexual  0.877694  0.69743    0.180264\n",
       "44        catholic  0.823846  0.69743    0.126417\n",
       "45           older  0.811825  0.69743    0.114396\n",
       "46       paralyzed  0.825795  0.69743    0.128366"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_auc = roc_auc_score(test_labels, ROC_pred)\n",
    "terms_auc = []\n",
    "identity_terms = []\n",
    "for identity_term in set(terms):\n",
    "    term_data = df_test[df_test['Identity_Terms'] == identity_term].reset_index()\n",
    "    data = df_test.sample(n=len(term_data['Text']), random_state=0)\n",
    "    data = term_data.append(data, ignore_index=True)\n",
    "    y_true, y_pred = data['Label'].astype(int), data['prediction_scores']\n",
    "\n",
    "    try:\n",
    "        term_auc = roc_auc_score(y_true, y_pred.round())\n",
    "        terms_auc.append(term_auc)\n",
    "        identity_terms.append(identity_term)\n",
    "    except:\n",
    "        print(\"Error in \",identity_term)\n",
    "\n",
    "\n",
    "    \n",
    "eval_scores = pd.DataFrame(identity_terms, columns = ['Identity_Titles'])\n",
    "eval_scores['AUCt'] = terms_auc\n",
    "eval_scores['AUC'] = total_auc\n",
    "eval_scores['AUC - AUCt'] = abs(eval_scores['AUC'] - eval_scores['AUCt'])\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.5795999401480865\n"
     ]
    }
   ],
   "source": [
    "print(eval_scores['AUC - AUCt'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
