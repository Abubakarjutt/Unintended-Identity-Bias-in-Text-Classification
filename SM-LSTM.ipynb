{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings( 'ignore' )\n",
    "import gc\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import text, sequence\n",
    "\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.util import ngrams\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings( 'ignore' )\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "#from thundersvm import SVC\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, accuracy_score\n",
    "\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding\n",
    "from keras.layers import CuDNNGRU, CuDNNLSTM, Conv1D, Conv2D, Dense, Bidirectional, GRU, LSTM, MaxPool1D\n",
    "from keras.layers import SpatialDropout1D, Dropout, Concatenate, concatenate, Softmax, Flatten, Reshape\n",
    "from keras.layers import GlobalMaxPooling1D, GlobalAveragePooling1D, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.optimizers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from tensorflow.random import set_seed\n",
    "from numpy.random import seed\n",
    "import random\n",
    "\n",
    "\n",
    "seed_value = 0\n",
    "set_seed(seed_value)\n",
    "seed(seed_value)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "random.seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import All_RUT_Models\n",
    "import RUT_Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters for this model\n",
    "\n",
    "max_len = 150\n",
    "embed_size = 300\n",
    "pre_trained_flag = True\n",
    "embed_trainable = False\n",
    "emb_weights_init = 'glorot_normal'\n",
    "spdrpt = 0.40\n",
    "drpt = 0.2\n",
    "fc_weights_init = 'glorot_uniform'\n",
    "fc_act = 'elu'\n",
    "lr_rate = 0.001\n",
    "optimizer = 'adam'\n",
    "lstm_units = 130\n",
    "multi_gpu_flag = 0\n",
    "gpus = 2\n",
    "batch = 16\n",
    "nepochs = 10\n",
    "patience = 5\n",
    "decay = True\n",
    "decay_rate = 0.5\n",
    "decay_after = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddingfile = './General_Embeddings/glove.txt'\n",
    "#embeddingfile = './General_Embeddings/w2v_cbow.txt'\n",
    "#embeddingfile = './General_Embeddings/w2v_sg.txt'\n",
    "#embeddingfile = './General_Embeddings/ft_cbow.vec'\n",
    "embeddingfile = 'wiki-news-300d-1M.vec'\n",
    "\n",
    "embedding_matrix = []\n",
    "#max_features = 100000\n",
    "\n",
    "modelname = 'BLSTM_ft_sg'\n",
    "\n",
    "modelpath = './Models/' + modelname + '/'\n",
    "\n",
    "if not os.path.exists( modelpath ):\n",
    "    os.makedirs( modelpath )\n",
    "if not os.path.exists( './Results/' ):\n",
    "    os.makedirs( './Results/' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_lower_case(data):\n",
    "    # Convert the input text into lowercase text\n",
    "    return np.char.lower(str(data))\n",
    "\n",
    "def remove_stop_words(data):\n",
    "    # Tokenize the input text and remove stopwords from the corpus\n",
    "    stop_words = stopwords.words('english')\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in words:\n",
    "        if w not in stop_words and len(w) > 3:\n",
    "            new_text = new_text + \" \" + lemmatizer.lemmatize(w)\n",
    "    return new_text\n",
    "\n",
    "def remove_punctuation(data):\n",
    "    # Remove punctuations defined below from input text\n",
    "    symbols = \"!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n\"\n",
    "    for i in range(len(symbols)):\n",
    "        data = np.char.replace(data, symbols[i], ' ')\n",
    "        data = np.char.replace(data, \"  \", \" \")\n",
    "    data = np.char.replace(data, ',', '')\n",
    "    return data\n",
    "\n",
    "def remove_apostrophe(data):\n",
    "    # Remove apostrophe from the input text\n",
    "    return np.char.replace(data, \"'\", \"\")\n",
    "\n",
    "def preprocess(data):\n",
    "    # Preprocess the input text\n",
    "    data = convert_lower_case(data)\n",
    "    data = remove_punctuation(data) #remove comma seperately\n",
    "    data = remove_apostrophe(data)\n",
    "    data = remove_stop_words(data)\n",
    "    return data\n",
    "\n",
    "def get_tokens(dataframe, column):\n",
    "    tokens = []\n",
    "    for i in tqdm_notebook(dataframe[column][:]):\n",
    "        _tokens = word_tokenize(preprocess(str(i)))\n",
    "        tokens.append(_tokens)\n",
    "        \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bffb4c0da47243f9b0df1b8bf1b48327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=95692.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ac1f55cfde64bfb8aade8fa5056d243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=76564.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "152ac6f899914ae18fc451376b4e3686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=76564.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('data\\\\wiki_train.csv')\n",
    "train_data = train_data.dropna(axis = 0)\n",
    "#train_data = train_data.sample(n=100000, random_state=0)\n",
    "train_data['toxicity'] = train_data['toxicity'].round()\n",
    "\n",
    "df_test = pd.read_csv('test_data.csv')\n",
    "df_test.loc[df_test['Label'] == 'BAD', 'Label'] = 1\n",
    "df_test.loc[df_test['Label'] == 'NOT_BAD', 'Label'] = 0\n",
    "\n",
    "\n",
    "train_feature = get_tokens(train_data, 'comment')\n",
    "train_label = train_data['toxicity']\n",
    "\n",
    "test_feature = get_tokens(df_test, 'Text')\n",
    "test_label = df_test['Label']\n",
    "\n",
    "identity_terms = []\n",
    "for i in tqdm_notebook(range(len(df_test['Text']))):\n",
    "    _comment = df_test.loc[i,  'Text'].split(\" \")\n",
    "    if len(_comment) < 3:\n",
    "        _term = _comment[1]\n",
    "        identity_terms.append(_term)\n",
    "identity_terms = list(set(identity_terms))\n",
    "\n",
    "\n",
    "terms = []\n",
    "for i in range(len(df_test['Text'])):\n",
    "    _text = df_test.loc[i, 'Text'].split(' ')\n",
    "    _term = list(set(_text).intersection(set(identity_terms)))\n",
    "    if len(_term) > 0:\n",
    "        terms.append(_term[0])\n",
    "    else:\n",
    "        terms.append(np.nan)\n",
    "        \n",
    "df_test['Identity_Terms'] = terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold( n_splits=5, random_state=0, shuffle=True )\n",
    "print(skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124996\n",
      "124996\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_feature)\n",
    "train_features = tokenizer.texts_to_sequences(train_feature)\n",
    "train_features = pad_sequences(train_features, maxlen = 128, dtype=\"int32\")\n",
    "train_features_vocab_size = len(tokenizer.word_index) + 1\n",
    "print(train_features_vocab_size)\n",
    "\n",
    "train_labels = tf.convert_to_tensor(train_label, dtype=\"int32\")\n",
    "\n",
    "test_features = tokenizer.texts_to_sequences(test_feature)\n",
    "test_features = pad_sequences(test_features, maxlen = 128, dtype=\"int32\")\n",
    "features_vocab_size = len(tokenizer.word_index) + 1\n",
    "print(features_vocab_size)\n",
    "\n",
    "test_labels = tf.convert_to_tensor(test_label, dtype=\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coefs( word, *arr ):\n",
    "    return word, np.asarray( arr, dtype='float32' )\n",
    "\n",
    "def get_vectors( tokenizer ):\n",
    "    word_index = tokenizer.word_index\n",
    "    num_words = min( len(tokenizer.word_index) + 1, len( word_index ) + 1 )\n",
    "    embedding_matrix = np.zeros( ( num_words, embed_size ) )\n",
    "    for word, i in word_index.items(  ):\n",
    "        if i >= len(tokenizer.word_index) + 1:\n",
    "            continue\n",
    "        embedding_vector = embeddings_index.get( word )\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    gc.collect()\n",
    "    return embedding_matrix\n",
    "\n",
    "if pre_trained_flag == True:\n",
    "    embeddings_index = dict( get_coefs( *o.rstrip().rsplit(' ') ) for o in open( embeddingfile, encoding='utf-8' ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "\n",
    "\n",
    "\n",
    "checkpoint_filepath = 'checkpoints/model.h5'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_false_positives',\n",
    "    mode='min',\n",
    "    save_best_only=True,\n",
    "    verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "embedding_matrix = get_vectors( tokenizer=tokenizer)\n",
    "\n",
    "inputs = tf.keras.Input(shape=(None,), dtype=\"int32\")\n",
    "\n",
    "x = tf.keras.layers.Embedding( input_dim=len(tokenizer.word_index)+1, output_dim=embed_size,\n",
    "                      weights=[embedding_matrix], trainable=embed_trainable, name='Embedding' )(inputs)\n",
    "x = tf.keras.layers.SpatialDropout1D( spdrpt, name='SpatialDropout1D' )( x )\n",
    "x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128))(x)\n",
    "x =  tf.keras.layers.Dropout( drpt, name='Dropout' )( x )\n",
    "fc1 =  tf.keras.layers.Dense( 128, activation=fc_act, kernel_initializer=fc_weights_init, name='FC1' )( x )\n",
    "fc2 = tf.keras.layers.Dense( 64, activation=fc_act, kernel_initializer=fc_weights_init, name='FC2')( fc1 )\n",
    "outputs =  tf.keras.layers.Dense( 1, activation='sigmoid', name='Output' )( fc2 )\n",
    "model = tf.keras.Model(inputs = inputs, outputs = outputs)\n",
    "\n",
    "model.compile( loss='binary_crossentropy', optimizer=optimizer, metrics = ['accuracy',tf.keras.metrics.AUC(), tf.keras.metrics.FalsePositives(thresholds=None, name=None, dtype=None)] )\n",
    "\n",
    "xtrain, xval, ytrain, yval = train_test_split( train_features, train_label, test_size=0.25, random_state=0 )\n",
    "\n",
    "hist = model.fit( xtrain, ytrain, batch_size=batch, validation_data=( xval,yval ),\n",
    "                     epochs=nepochs, verbose=1, callbacks=[model_checkpoint_callback])\n",
    "model.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('checkpoints/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45fd2b425fbb4ebdb9af4d01abfd9447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=95692.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "xf_positive = 0\n",
    "xd_positive = 0\n",
    "xf_total = 0\n",
    "xd_total = 0\n",
    "\n",
    "for i in tqdm_notebook(range(len(train_feature))):\n",
    "    if(train_labels[i] == 1 and len(list(set(train_feature[i]).intersection(set(terms)))) > 0):\n",
    "        xd_positive += 1\n",
    "        xd_total += 1\n",
    "    elif(len(list(set(train_feature[i]).intersection(set(terms)))) > 0):\n",
    "        xd_total += 1\n",
    "    elif(train_labels[i] == 1 and len(list(set(train_feature[i]).intersection(set(terms))))==0):\n",
    "        xf_positive += 1\n",
    "        xf_total += 1\n",
    "    elif(len(list(set(train_feature[i]).intersection(set(terms))))== 0):\n",
    "        xf_total += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.009719561164268795"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf = xf_positive / xf_total\n",
    "pd = xd_positive / xd_total\n",
    "discrimination = pf - pd\n",
    "discrimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a5dd862a1a94d46804f86f7543e96de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=95692.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(train_features)\n",
    "xf_positive = 0\n",
    "xd_positive = 0\n",
    "xf_total = 0\n",
    "xd_total = 0\n",
    "\n",
    "for i in tqdm_notebook(range(len(train_feature))):\n",
    "    if(pred[i].round() == 1 and len(list(set(train_feature[i]).intersection(set(terms)))) > 0):\n",
    "        xd_positive += 1\n",
    "        xd_total += 1\n",
    "    elif(len(list(set(train_feature[i]).intersection(set(terms)))) > 0):\n",
    "        xd_total += 1\n",
    "    elif(pred[i].round() == 1 and len(list(set(train_feature[i]).intersection(set(terms))))==0):\n",
    "        xf_positive += 1\n",
    "        xf_total += 1\n",
    "    elif(len(list(set(train_feature[i]).intersection(set(terms))))== 0):\n",
    "        xf_total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004362583351552665"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf = xf_positive / xf_total\n",
    "pd = xd_positive / xd_total\n",
    "discrimination = pf - pd\n",
    "discrimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8403949636905073"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(test_features)\n",
    "df_test['prediction_scores'] = pred\n",
    "accuracy_score(test_labels, pred.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25b2009a3eaa46f5987d83aaf11a1ff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=76564.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "xf_positive = 0\n",
    "xd_positive = 0\n",
    "xf_total = 0\n",
    "xd_total = 0\n",
    "\n",
    "for i in tqdm_notebook(range(len(test_feature))):\n",
    "    if(pred[i].round() == 1 and len(list(set(test_feature[i]).intersection(set(terms)))) > 0):\n",
    "        xd_positive += 1\n",
    "        xd_total += 1\n",
    "    elif(len(list(set(test_feature[i]).intersection(set(terms)))) > 0):\n",
    "        xd_total += 1\n",
    "    elif(pred[i].round() == 1 and len(list(set(test_feature[i]).intersection(set(terms))))==0):\n",
    "        xf_positive += 1\n",
    "        xf_total += 1\n",
    "    elif(len(list(set(test_feature[i]).intersection(set(terms))))== 0):\n",
    "        xf_total += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.05619392829528075"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf = xf_positive / xf_total\n",
    "pd = xd_positive / xd_total\n",
    "discrimination = pf - pd\n",
    "discrimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in  nan\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Identity_Titles</th>\n",
       "      <th>Identity_Term_False_Positive</th>\n",
       "      <th>Total_False_Positive</th>\n",
       "      <th>Identity_Term_False_Negatives</th>\n",
       "      <th>Total_False_Negative</th>\n",
       "      <th>FPR - FPRt</th>\n",
       "      <th>FNR - FNRt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jewish</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.336856</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.026632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>black</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.212682</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.097542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>younger</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.414795</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.104571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>old</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.357992</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.047768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>asian</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.233818</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.076406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.221929</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.088295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>blind</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.233818</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.076406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>female</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.286658</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.023566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>catholic</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.365918</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.055694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>trans</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.229855</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.080369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>young</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.335535</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.025311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>teenage</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.287979</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.022245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>lgbt</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.417437</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.107213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>white</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.229855</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.080369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mexican</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.350066</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.039842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>latino</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.174373</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.135852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>hispanic</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.233818</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.076406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>indian</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.414795</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.104571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gay</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.357992</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.047768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>american</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.412814</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.102590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>lesbian</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.110964</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.199260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>canadian</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.463672</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.153448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>christian</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.342140</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.031916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>straight</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.232497</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.077727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>muslim</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.346103</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.035879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>taoist</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.357992</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.047768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>nonbinary</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.357992</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.047768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>queer</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.117569</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.192655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>heterosexual</td>\n",
       "      <td>0.128137</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.014531</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.119151</td>\n",
       "      <td>0.295693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>transgender</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.297226</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.012998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>japanese</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.363276</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.053052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>millenial</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.365918</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.055694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>latinx</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.357992</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.047768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>homosexual</td>\n",
       "      <td>0.326288</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.317302</td>\n",
       "      <td>0.310224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>sikh</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.356671</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.046447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>older</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.414795</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.104571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>elderly</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.355350</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.045126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>latina</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.294584</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.015640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>paralyzed</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.357992</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.047768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>buddhist</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.354029</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.043805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>lgbtq</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.400264</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.090040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>chinese</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.351387</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.041163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>bisexual</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.116248</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.193976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>deaf</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.284016</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.026208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>european</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.368560</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.058336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>african</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.357992</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.047768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>protestant</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.298547</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.011677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Identity_Titles  Identity_Term_False_Positive  Total_False_Positive  \\\n",
       "0           jewish                      0.000000              0.008986   \n",
       "1            black                      0.000000              0.008986   \n",
       "2          younger                      0.000000              0.008986   \n",
       "3              old                      0.000000              0.008986   \n",
       "4            asian                      0.000000              0.008986   \n",
       "5             male                      0.000000              0.008986   \n",
       "6            blind                      0.000000              0.008986   \n",
       "7           female                      0.000000              0.008986   \n",
       "8         catholic                      0.000000              0.008986   \n",
       "9            trans                      0.000000              0.008986   \n",
       "10           young                      0.000000              0.008986   \n",
       "11         teenage                      0.000000              0.008986   \n",
       "12            lgbt                      0.000000              0.008986   \n",
       "13           white                      0.000000              0.008986   \n",
       "14         mexican                      0.000000              0.008986   \n",
       "15          latino                      0.000000              0.008986   \n",
       "16        hispanic                      0.000000              0.008986   \n",
       "17          indian                      0.000000              0.008986   \n",
       "18             gay                      0.000000              0.008986   \n",
       "19        american                      0.000000              0.008986   \n",
       "20         lesbian                      0.000000              0.008986   \n",
       "21        canadian                      0.000000              0.008986   \n",
       "22       christian                      0.000000              0.008986   \n",
       "23        straight                      0.000000              0.008986   \n",
       "24          muslim                      0.000000              0.008986   \n",
       "25          taoist                      0.000000              0.008986   \n",
       "26       nonbinary                      0.000000              0.008986   \n",
       "27           queer                      0.000000              0.008986   \n",
       "28    heterosexual                      0.128137              0.008986   \n",
       "29     transgender                      0.000000              0.008986   \n",
       "30        japanese                      0.000000              0.008986   \n",
       "31       millenial                      0.000000              0.008986   \n",
       "32          latinx                      0.000000              0.008986   \n",
       "33      homosexual                      0.326288              0.008986   \n",
       "34            sikh                      0.000000              0.008986   \n",
       "35           older                      0.000000              0.008986   \n",
       "36         elderly                      0.000000              0.008986   \n",
       "37          latina                      0.000000              0.008986   \n",
       "38       paralyzed                      0.000000              0.008986   \n",
       "39        buddhist                      0.000000              0.008986   \n",
       "40           lgbtq                      0.000000              0.008986   \n",
       "41         chinese                      0.000000              0.008986   \n",
       "42        bisexual                      0.000000              0.008986   \n",
       "43            deaf                      0.000000              0.008986   \n",
       "44        european                      0.000000              0.008986   \n",
       "45         african                      0.000000              0.008986   \n",
       "46      protestant                      0.000000              0.008986   \n",
       "\n",
       "    Identity_Term_False_Negatives  Total_False_Negative  FPR - FPRt  \\\n",
       "0                        0.336856              0.310224    0.008986   \n",
       "1                        0.212682              0.310224    0.008986   \n",
       "2                        0.414795              0.310224    0.008986   \n",
       "3                        0.357992              0.310224    0.008986   \n",
       "4                        0.233818              0.310224    0.008986   \n",
       "5                        0.221929              0.310224    0.008986   \n",
       "6                        0.233818              0.310224    0.008986   \n",
       "7                        0.286658              0.310224    0.008986   \n",
       "8                        0.365918              0.310224    0.008986   \n",
       "9                        0.229855              0.310224    0.008986   \n",
       "10                       0.335535              0.310224    0.008986   \n",
       "11                       0.287979              0.310224    0.008986   \n",
       "12                       0.417437              0.310224    0.008986   \n",
       "13                       0.229855              0.310224    0.008986   \n",
       "14                       0.350066              0.310224    0.008986   \n",
       "15                       0.174373              0.310224    0.008986   \n",
       "16                       0.233818              0.310224    0.008986   \n",
       "17                       0.414795              0.310224    0.008986   \n",
       "18                       0.357992              0.310224    0.008986   \n",
       "19                       0.412814              0.310224    0.008986   \n",
       "20                       0.110964              0.310224    0.008986   \n",
       "21                       0.463672              0.310224    0.008986   \n",
       "22                       0.342140              0.310224    0.008986   \n",
       "23                       0.232497              0.310224    0.008986   \n",
       "24                       0.346103              0.310224    0.008986   \n",
       "25                       0.357992              0.310224    0.008986   \n",
       "26                       0.357992              0.310224    0.008986   \n",
       "27                       0.117569              0.310224    0.008986   \n",
       "28                       0.014531              0.310224    0.119151   \n",
       "29                       0.297226              0.310224    0.008986   \n",
       "30                       0.363276              0.310224    0.008986   \n",
       "31                       0.365918              0.310224    0.008986   \n",
       "32                       0.357992              0.310224    0.008986   \n",
       "33                       0.000000              0.310224    0.317302   \n",
       "34                       0.356671              0.310224    0.008986   \n",
       "35                       0.414795              0.310224    0.008986   \n",
       "36                       0.355350              0.310224    0.008986   \n",
       "37                       0.294584              0.310224    0.008986   \n",
       "38                       0.357992              0.310224    0.008986   \n",
       "39                       0.354029              0.310224    0.008986   \n",
       "40                       0.400264              0.310224    0.008986   \n",
       "41                       0.351387              0.310224    0.008986   \n",
       "42                       0.116248              0.310224    0.008986   \n",
       "43                       0.284016              0.310224    0.008986   \n",
       "44                       0.368560              0.310224    0.008986   \n",
       "45                       0.357992              0.310224    0.008986   \n",
       "46                       0.298547              0.310224    0.008986   \n",
       "\n",
       "    FNR - FNRt  \n",
       "0     0.026632  \n",
       "1     0.097542  \n",
       "2     0.104571  \n",
       "3     0.047768  \n",
       "4     0.076406  \n",
       "5     0.088295  \n",
       "6     0.076406  \n",
       "7     0.023566  \n",
       "8     0.055694  \n",
       "9     0.080369  \n",
       "10    0.025311  \n",
       "11    0.022245  \n",
       "12    0.107213  \n",
       "13    0.080369  \n",
       "14    0.039842  \n",
       "15    0.135852  \n",
       "16    0.076406  \n",
       "17    0.104571  \n",
       "18    0.047768  \n",
       "19    0.102590  \n",
       "20    0.199260  \n",
       "21    0.153448  \n",
       "22    0.031916  \n",
       "23    0.077727  \n",
       "24    0.035879  \n",
       "25    0.047768  \n",
       "26    0.047768  \n",
       "27    0.192655  \n",
       "28    0.295693  \n",
       "29    0.012998  \n",
       "30    0.053052  \n",
       "31    0.055694  \n",
       "32    0.047768  \n",
       "33    0.310224  \n",
       "34    0.046447  \n",
       "35    0.104571  \n",
       "36    0.045126  \n",
       "37    0.015640  \n",
       "38    0.047768  \n",
       "39    0.043805  \n",
       "40    0.090040  \n",
       "41    0.041163  \n",
       "42    0.193976  \n",
       "43    0.026208  \n",
       "44    0.058336  \n",
       "45    0.047768  \n",
       "46    0.011677  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def perf_measure(y_actual, y_hat):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(y_hat)): \n",
    "        if y_actual[i]==y_hat[i]==1:\n",
    "           TP += 1\n",
    "        if y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n",
    "           FP += 1\n",
    "        if y_actual[i]==y_hat[i]==0:\n",
    "           TN += 1\n",
    "        if y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n",
    "           FN += 1\n",
    "\n",
    "    return(TN, FP, FN, TP)\n",
    "\n",
    "\n",
    "\n",
    "total_tn, total_fp, total_fn, total_tp = confusion_matrix(test_labels, pred.round()).ravel()\n",
    "total_fpr = total_fp / (total_fp + total_tn )\n",
    "total_fnr = total_fn / (total_fn + total_tp)\n",
    "false_positive = []\n",
    "false_negative = []\n",
    "identity_terms = []\n",
    "for identity_term in set(terms):\n",
    "    data = df_test[df_test['Identity_Terms'] == identity_term].reset_index()\n",
    "    y_true, y_pred = data['Label'].astype(int), data['prediction_scores']\n",
    "    tn, fp, fn, tp = perf_measure(y_true, y_pred.round())\n",
    "    try:\n",
    "        fpr = fp / (fp + tn)\n",
    "        fnr = fn / (fn + tp)\n",
    "        false_positive.append(fpr)\n",
    "        false_negative.append(fnr)\n",
    "        identity_terms.append(identity_term)\n",
    "    except:\n",
    "        print(\"Error in \", identity_term)\n",
    "\n",
    "    \n",
    "eval_scores = pd.DataFrame(identity_terms, columns = ['Identity_Titles'])\n",
    "eval_scores['Identity_Term_False_Positive'] = false_positive\n",
    "eval_scores['Total_False_Positive'] = total_fpr\n",
    "eval_scores['Identity_Term_False_Negatives'] = false_negative\n",
    "eval_scores['Total_False_Negative'] = total_fnr\n",
    "eval_scores['FPR - FPRt'] = abs(total_fpr - eval_scores['Identity_Term_False_Positive'])\n",
    "eval_scores['FNR - FNRt'] = abs(total_fnr - eval_scores['Identity_Term_False_Negatives'])\n",
    "eval_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8408210583808385, 3.7537943925414243)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_scores['FPR - FPRt'].sum(), eval_scores['FNR - FNRt'].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in  nan\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Identity_Titles</th>\n",
       "      <th>AUCt</th>\n",
       "      <th>AUC</th>\n",
       "      <th>AUC - AUCt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jewish</td>\n",
       "      <td>0.830994</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.009401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>black</td>\n",
       "      <td>0.861533</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.021138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>younger</td>\n",
       "      <td>0.811825</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.028570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>old</td>\n",
       "      <td>0.825795</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.014599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>asian</td>\n",
       "      <td>0.856335</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.015940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>male</td>\n",
       "      <td>0.859259</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.018864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>blind</td>\n",
       "      <td>0.856335</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.015940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>female</td>\n",
       "      <td>0.843339</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.002944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>catholic</td>\n",
       "      <td>0.823846</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.016549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>trans</td>\n",
       "      <td>0.857309</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.016914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>young</td>\n",
       "      <td>0.831319</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.009076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>teenage</td>\n",
       "      <td>0.843014</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.002620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>lgbt</td>\n",
       "      <td>0.811176</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.029219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>white</td>\n",
       "      <td>0.857309</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.016914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mexican</td>\n",
       "      <td>0.827745</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.012650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>latino</td>\n",
       "      <td>0.870955</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.030560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>hispanic</td>\n",
       "      <td>0.856335</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.015940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>indian</td>\n",
       "      <td>0.811825</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.028570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gay</td>\n",
       "      <td>0.825795</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.014599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>american</td>\n",
       "      <td>0.815523</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.024872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>lesbian</td>\n",
       "      <td>0.886549</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.046154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>canadian</td>\n",
       "      <td>0.799805</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.040590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>christian</td>\n",
       "      <td>0.829694</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.010701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>straight</td>\n",
       "      <td>0.856660</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.016265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>muslim</td>\n",
       "      <td>0.828719</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.011675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>taoist</td>\n",
       "      <td>0.825795</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.014599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>nonbinary</td>\n",
       "      <td>0.825795</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.014599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>queer</td>\n",
       "      <td>0.884925</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.044530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>heterosexual</td>\n",
       "      <td>0.877694</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.037299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>transgender</td>\n",
       "      <td>0.840740</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.000345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>japanese</td>\n",
       "      <td>0.824496</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.015899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>millenial</td>\n",
       "      <td>0.823846</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.016549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>latinx</td>\n",
       "      <td>0.825795</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.014599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>homosexual</td>\n",
       "      <td>0.830898</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.009497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>sikh</td>\n",
       "      <td>0.826120</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.014275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>older</td>\n",
       "      <td>0.811825</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.028570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>elderly</td>\n",
       "      <td>0.826445</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.013950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>latina</td>\n",
       "      <td>0.841390</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.000995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>paralyzed</td>\n",
       "      <td>0.825795</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.014599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>buddhist</td>\n",
       "      <td>0.826770</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.013625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>lgbtq</td>\n",
       "      <td>0.815399</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.024996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>chinese</td>\n",
       "      <td>0.827420</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.012975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>bisexual</td>\n",
       "      <td>0.885250</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.044855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>deaf</td>\n",
       "      <td>0.843989</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.003594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>european</td>\n",
       "      <td>0.823196</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.017199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>african</td>\n",
       "      <td>0.825795</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.014599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>protestant</td>\n",
       "      <td>0.840415</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Identity_Titles      AUCt       AUC  AUC - AUCt\n",
       "0           jewish  0.830994  0.840395    0.009401\n",
       "1            black  0.861533  0.840395    0.021138\n",
       "2          younger  0.811825  0.840395    0.028570\n",
       "3              old  0.825795  0.840395    0.014599\n",
       "4            asian  0.856335  0.840395    0.015940\n",
       "5             male  0.859259  0.840395    0.018864\n",
       "6            blind  0.856335  0.840395    0.015940\n",
       "7           female  0.843339  0.840395    0.002944\n",
       "8         catholic  0.823846  0.840395    0.016549\n",
       "9            trans  0.857309  0.840395    0.016914\n",
       "10           young  0.831319  0.840395    0.009076\n",
       "11         teenage  0.843014  0.840395    0.002620\n",
       "12            lgbt  0.811176  0.840395    0.029219\n",
       "13           white  0.857309  0.840395    0.016914\n",
       "14         mexican  0.827745  0.840395    0.012650\n",
       "15          latino  0.870955  0.840395    0.030560\n",
       "16        hispanic  0.856335  0.840395    0.015940\n",
       "17          indian  0.811825  0.840395    0.028570\n",
       "18             gay  0.825795  0.840395    0.014599\n",
       "19        american  0.815523  0.840395    0.024872\n",
       "20         lesbian  0.886549  0.840395    0.046154\n",
       "21        canadian  0.799805  0.840395    0.040590\n",
       "22       christian  0.829694  0.840395    0.010701\n",
       "23        straight  0.856660  0.840395    0.016265\n",
       "24          muslim  0.828719  0.840395    0.011675\n",
       "25          taoist  0.825795  0.840395    0.014599\n",
       "26       nonbinary  0.825795  0.840395    0.014599\n",
       "27           queer  0.884925  0.840395    0.044530\n",
       "28    heterosexual  0.877694  0.840395    0.037299\n",
       "29     transgender  0.840740  0.840395    0.000345\n",
       "30        japanese  0.824496  0.840395    0.015899\n",
       "31       millenial  0.823846  0.840395    0.016549\n",
       "32          latinx  0.825795  0.840395    0.014599\n",
       "33      homosexual  0.830898  0.840395    0.009497\n",
       "34            sikh  0.826120  0.840395    0.014275\n",
       "35           older  0.811825  0.840395    0.028570\n",
       "36         elderly  0.826445  0.840395    0.013950\n",
       "37          latina  0.841390  0.840395    0.000995\n",
       "38       paralyzed  0.825795  0.840395    0.014599\n",
       "39        buddhist  0.826770  0.840395    0.013625\n",
       "40           lgbtq  0.815399  0.840395    0.024996\n",
       "41         chinese  0.827420  0.840395    0.012975\n",
       "42        bisexual  0.885250  0.840395    0.044855\n",
       "43            deaf  0.843989  0.840395    0.003594\n",
       "44        european  0.823196  0.840395    0.017199\n",
       "45         african  0.825795  0.840395    0.014599\n",
       "46      protestant  0.840415  0.840395    0.000020"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_auc = roc_auc_score(test_labels, pred.round())\n",
    "terms_auc = []\n",
    "identity_terms = []\n",
    "for identity_term in set(terms):\n",
    "    term_data = df_test[df_test['Identity_Terms'] == identity_term].reset_index()\n",
    "    data = df_test.sample(n=len(term_data['Text']), random_state=0)\n",
    "    data = term_data.append(data, ignore_index=True)\n",
    "    y_true, y_pred = data['Label'].astype(int), data['prediction_scores']\n",
    "\n",
    "    try:\n",
    "        term_auc = roc_auc_score(y_true, y_pred.round())\n",
    "        terms_auc.append(term_auc)\n",
    "        identity_terms.append(identity_term)\n",
    "    except:\n",
    "        print(\"Error in \",identity_term)\n",
    "\n",
    "\n",
    "    \n",
    "eval_scores = pd.DataFrame(identity_terms, columns = ['Identity_Titles'])\n",
    "eval_scores['AUCt'] = terms_auc\n",
    "eval_scores['AUC'] = total_auc\n",
    "eval_scores['AUC - AUCt'] = abs(eval_scores['AUC'] - eval_scores['AUCt'])\n",
    "eval_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8434344934908964\n"
     ]
    }
   ],
   "source": [
    "print(eval_scores['AUC - AUCt'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "theta = 0.55\n",
    "features = []\n",
    "labels = []\n",
    "for i in tqdm_notebook(range(len(test_features[:]))):\n",
    "    p_positive = pred[i]\n",
    "    p_negative = 1 - p_positive\n",
    "    feature = test_features[i]\n",
    "    label = df_test.loc[i, 'Label']\n",
    "    #feature = [np.hstack((feature, label))]\n",
    "    if max(p_positive, p_negative) < theta:\n",
    "        features.append(feature)\n",
    "        labels.append(label)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNN = KNeighborsClassifier(n_neighbors=3, weights = 'distance',n_jobs = -1)\n",
    "KNN.fit(features, labels)\n",
    "\n",
    "SM_pred = []\n",
    "indices = []\n",
    "for i in tqdm_notebook(range(len(test_features[:]))):\n",
    "    p_positive = pred[i]\n",
    "    p_negative = 1 - p_positive\n",
    "    feature = [test_features[i]]\n",
    "    label = df_test.loc[i, 'Label']\n",
    "    #feature = [np.hstack((feature, label))]\n",
    "    if max(p_positive, p_negative) < theta:\n",
    "        prediction = KNN.predict(feature)\n",
    "        SM_pred.append(int(prediction))\n",
    "    else:\n",
    "        SM_pred.append(int(p_positive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "688c6853108448e5b9223d37747e602d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=76564.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNN = KNeighborsClassifier(n_neighbors=3, weights = 'distance',n_jobs = -1)\n",
    "KNN.fit(test_features, test_labels)\n",
    "\n",
    "theta = 0.8\n",
    "SM_pred = []\n",
    "for i in tqdm_notebook(range(len(test_features[:]))):\n",
    "    p_positive = pred[i]\n",
    "    p_negative = 1 - p_positive\n",
    "    feature = [test_features[i]]\n",
    "    label = df_test.loc[i, 'Label']\n",
    "    #feature = [np.hstack((feature, label))]\n",
    "    if max(p_positive, p_negative) < theta:\n",
    "        prediction = KNN.predict(feature)\n",
    "        SM_pred.append(prediction)\n",
    "    else:\n",
    "        SM_pred.append(pred[i].round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c957ac6d23a4d09a21bb6f3866ad07e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=76564.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "xf_positive = 0\n",
    "xd_positive = 0\n",
    "xf_total = 0\n",
    "xd_total = 0\n",
    "\n",
    "for i in tqdm_notebook(range(len(test_feature))):\n",
    "    if(SM_pred[i] == 1 and len(list(set(test_feature[i]).intersection(set(terms)))) > 0):\n",
    "        xd_positive += 1\n",
    "        xd_total += 1\n",
    "    elif(len(list(set(test_feature[i]).intersection(set(terms)))) > 0):\n",
    "        xd_total += 1\n",
    "    elif(SM_pred[i] == 1 and len(list(set(test_feature[i]).intersection(set(terms))))== 0):\n",
    "        xf_positive += 1\n",
    "        xf_total += 1\n",
    "    elif(len(list(set(test_feature[i]).intersection(set(terms))))== 0):\n",
    "        xf_total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.023022536081933442"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf = xf_positive / xf_total\n",
    "pd = xd_positive / xd_total\n",
    "discrimination = pf - pd\n",
    "discrimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9660284206676767"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_labels, SM_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in  nan\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Identity_Titles</th>\n",
       "      <th>Identity_Term_False_Positive</th>\n",
       "      <th>Total_False_Positive</th>\n",
       "      <th>Identity_Term_False_Negatives</th>\n",
       "      <th>Total_False_Negative</th>\n",
       "      <th>FPR - FPRt</th>\n",
       "      <th>FNR - FNRt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jewish</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.336856</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.268913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>black</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.212682</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.144738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>younger</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.414795</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.346852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>old</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.357992</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>asian</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.233818</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.165875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.221929</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>blind</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.233818</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.165875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>female</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.286658</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.218715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>catholic</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.365918</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.297975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>trans</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.229855</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.161912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>young</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.335535</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.267592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>teenage</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.287979</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.220036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>lgbt</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.417437</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.349494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>white</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.229855</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.161912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mexican</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.350066</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.282123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>latino</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.174373</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>hispanic</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.233818</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.165875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>indian</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.414795</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.346852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gay</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.357992</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>american</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412814</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.344871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>lesbian</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.110964</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>canadian</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.463672</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.395729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>christian</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.342140</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.274197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>straight</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232497</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.164554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>muslim</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.346103</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.278160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>taoist</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.357992</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>nonbinary</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.357992</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>queer</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117569</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>heterosexual</td>\n",
       "      <td>0.128137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014531</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.128137</td>\n",
       "      <td>0.053412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>transgender</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.297226</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.229283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>japanese</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363276</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.295333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>millenial</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.365918</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.297975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>latinx</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.357992</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>homosexual</td>\n",
       "      <td>0.326288</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.326288</td>\n",
       "      <td>0.067943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>sikh</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.356671</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.288728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>older</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.414795</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.346852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>elderly</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.355350</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.287407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>latina</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.294584</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.226641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>paralyzed</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.357992</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>buddhist</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.354029</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.286086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>lgbtq</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400264</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.332321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>chinese</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.351387</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.283444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>bisexual</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.116248</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>deaf</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.284016</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.216073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>european</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.368560</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>african</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.357992</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>protestant</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.298547</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.230604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Identity_Titles  Identity_Term_False_Positive  Total_False_Positive  \\\n",
       "0           jewish                      0.000000                   0.0   \n",
       "1            black                      0.000000                   0.0   \n",
       "2          younger                      0.000000                   0.0   \n",
       "3              old                      0.000000                   0.0   \n",
       "4            asian                      0.000000                   0.0   \n",
       "5             male                      0.000000                   0.0   \n",
       "6            blind                      0.000000                   0.0   \n",
       "7           female                      0.000000                   0.0   \n",
       "8         catholic                      0.000000                   0.0   \n",
       "9            trans                      0.000000                   0.0   \n",
       "10           young                      0.000000                   0.0   \n",
       "11         teenage                      0.000000                   0.0   \n",
       "12            lgbt                      0.000000                   0.0   \n",
       "13           white                      0.000000                   0.0   \n",
       "14         mexican                      0.000000                   0.0   \n",
       "15          latino                      0.000000                   0.0   \n",
       "16        hispanic                      0.000000                   0.0   \n",
       "17          indian                      0.000000                   0.0   \n",
       "18             gay                      0.000000                   0.0   \n",
       "19        american                      0.000000                   0.0   \n",
       "20         lesbian                      0.000000                   0.0   \n",
       "21        canadian                      0.000000                   0.0   \n",
       "22       christian                      0.000000                   0.0   \n",
       "23        straight                      0.000000                   0.0   \n",
       "24          muslim                      0.000000                   0.0   \n",
       "25          taoist                      0.000000                   0.0   \n",
       "26       nonbinary                      0.000000                   0.0   \n",
       "27           queer                      0.000000                   0.0   \n",
       "28    heterosexual                      0.128137                   0.0   \n",
       "29     transgender                      0.000000                   0.0   \n",
       "30        japanese                      0.000000                   0.0   \n",
       "31       millenial                      0.000000                   0.0   \n",
       "32          latinx                      0.000000                   0.0   \n",
       "33      homosexual                      0.326288                   0.0   \n",
       "34            sikh                      0.000000                   0.0   \n",
       "35           older                      0.000000                   0.0   \n",
       "36         elderly                      0.000000                   0.0   \n",
       "37          latina                      0.000000                   0.0   \n",
       "38       paralyzed                      0.000000                   0.0   \n",
       "39        buddhist                      0.000000                   0.0   \n",
       "40           lgbtq                      0.000000                   0.0   \n",
       "41         chinese                      0.000000                   0.0   \n",
       "42        bisexual                      0.000000                   0.0   \n",
       "43            deaf                      0.000000                   0.0   \n",
       "44        european                      0.000000                   0.0   \n",
       "45         african                      0.000000                   0.0   \n",
       "46      protestant                      0.000000                   0.0   \n",
       "\n",
       "    Identity_Term_False_Negatives  Total_False_Negative  FPR - FPRt  \\\n",
       "0                        0.336856              0.067943    0.000000   \n",
       "1                        0.212682              0.067943    0.000000   \n",
       "2                        0.414795              0.067943    0.000000   \n",
       "3                        0.357992              0.067943    0.000000   \n",
       "4                        0.233818              0.067943    0.000000   \n",
       "5                        0.221929              0.067943    0.000000   \n",
       "6                        0.233818              0.067943    0.000000   \n",
       "7                        0.286658              0.067943    0.000000   \n",
       "8                        0.365918              0.067943    0.000000   \n",
       "9                        0.229855              0.067943    0.000000   \n",
       "10                       0.335535              0.067943    0.000000   \n",
       "11                       0.287979              0.067943    0.000000   \n",
       "12                       0.417437              0.067943    0.000000   \n",
       "13                       0.229855              0.067943    0.000000   \n",
       "14                       0.350066              0.067943    0.000000   \n",
       "15                       0.174373              0.067943    0.000000   \n",
       "16                       0.233818              0.067943    0.000000   \n",
       "17                       0.414795              0.067943    0.000000   \n",
       "18                       0.357992              0.067943    0.000000   \n",
       "19                       0.412814              0.067943    0.000000   \n",
       "20                       0.110964              0.067943    0.000000   \n",
       "21                       0.463672              0.067943    0.000000   \n",
       "22                       0.342140              0.067943    0.000000   \n",
       "23                       0.232497              0.067943    0.000000   \n",
       "24                       0.346103              0.067943    0.000000   \n",
       "25                       0.357992              0.067943    0.000000   \n",
       "26                       0.357992              0.067943    0.000000   \n",
       "27                       0.117569              0.067943    0.000000   \n",
       "28                       0.014531              0.067943    0.128137   \n",
       "29                       0.297226              0.067943    0.000000   \n",
       "30                       0.363276              0.067943    0.000000   \n",
       "31                       0.365918              0.067943    0.000000   \n",
       "32                       0.357992              0.067943    0.000000   \n",
       "33                       0.000000              0.067943    0.326288   \n",
       "34                       0.356671              0.067943    0.000000   \n",
       "35                       0.414795              0.067943    0.000000   \n",
       "36                       0.355350              0.067943    0.000000   \n",
       "37                       0.294584              0.067943    0.000000   \n",
       "38                       0.357992              0.067943    0.000000   \n",
       "39                       0.354029              0.067943    0.000000   \n",
       "40                       0.400264              0.067943    0.000000   \n",
       "41                       0.351387              0.067943    0.000000   \n",
       "42                       0.116248              0.067943    0.000000   \n",
       "43                       0.284016              0.067943    0.000000   \n",
       "44                       0.368560              0.067943    0.000000   \n",
       "45                       0.357992              0.067943    0.000000   \n",
       "46                       0.298547              0.067943    0.000000   \n",
       "\n",
       "    FNR - FNRt  \n",
       "0     0.268913  \n",
       "1     0.144738  \n",
       "2     0.346852  \n",
       "3     0.290049  \n",
       "4     0.165875  \n",
       "5     0.153986  \n",
       "6     0.165875  \n",
       "7     0.218715  \n",
       "8     0.297975  \n",
       "9     0.161912  \n",
       "10    0.267592  \n",
       "11    0.220036  \n",
       "12    0.349494  \n",
       "13    0.161912  \n",
       "14    0.282123  \n",
       "15    0.106429  \n",
       "16    0.165875  \n",
       "17    0.346852  \n",
       "18    0.290049  \n",
       "19    0.344871  \n",
       "20    0.043021  \n",
       "21    0.395729  \n",
       "22    0.274197  \n",
       "23    0.164554  \n",
       "24    0.278160  \n",
       "25    0.290049  \n",
       "26    0.290049  \n",
       "27    0.049626  \n",
       "28    0.053412  \n",
       "29    0.229283  \n",
       "30    0.295333  \n",
       "31    0.297975  \n",
       "32    0.290049  \n",
       "33    0.067943  \n",
       "34    0.288728  \n",
       "35    0.346852  \n",
       "36    0.287407  \n",
       "37    0.226641  \n",
       "38    0.290049  \n",
       "39    0.286086  \n",
       "40    0.332321  \n",
       "41    0.283444  \n",
       "42    0.048305  \n",
       "43    0.216073  \n",
       "44    0.300617  \n",
       "45    0.290049  \n",
       "46    0.230604  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_data['prediction_scores'] = ROC_pred\n",
    "import pandas as pd\n",
    "total_tn, total_fp, total_fn, total_tp = confusion_matrix(test_labels, SM_pred).ravel()\n",
    "total_fpr = total_fp / (total_fp + total_tn )\n",
    "total_fnr = total_fn / (total_fn + total_tp)\n",
    "false_positive = []\n",
    "false_negative = []\n",
    "identity_terms = []\n",
    "for identity_term in set(terms):\n",
    "    data = df_test[df_test['Identity_Terms'] == identity_term].reset_index()\n",
    "    y_true, y_pred = data['Label'].astype(int), data['prediction_scores']\n",
    "    tn, fp, fn, tp = perf_measure(y_true, y_pred.round())\n",
    "    try:\n",
    "        fpr = fp / (fp + tn)\n",
    "        fnr = fn / (fn + tp)\n",
    "        false_positive.append(fpr)\n",
    "        false_negative.append(fnr)\n",
    "        identity_terms.append(identity_term)\n",
    "    except:\n",
    "        print(\"Error in \", identity_term)\n",
    "\n",
    "    \n",
    "eval_scores = pd.DataFrame(identity_terms, columns = ['Identity_Titles'])\n",
    "eval_scores['Identity_Term_False_Positive'] = false_positive\n",
    "eval_scores['Total_False_Positive'] = total_fpr\n",
    "eval_scores['Identity_Term_False_Negatives'] = false_negative\n",
    "eval_scores['Total_False_Negative'] = total_fnr\n",
    "eval_scores['FPR - FPRt'] = abs(total_fpr - eval_scores['Identity_Term_False_Positive'])\n",
    "eval_scores['FNR - FNRt'] = abs(total_fnr - eval_scores['Identity_Term_False_Negatives'])\n",
    "eval_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.45442536327608984, 11.196674032109762)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_scores['FPR - FPRt'].sum(), eval_scores['FNR - FNRt'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in  nan\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Identity_Titles</th>\n",
       "      <th>AUCt</th>\n",
       "      <th>AUC</th>\n",
       "      <th>AUC - AUCt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jewish</td>\n",
       "      <td>0.830994</td>\n",
       "      <td>0.966028</td>\n",
       "      <td>0.135035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>black</td>\n",
       "      <td>0.861533</td>\n",
       "      <td>0.966028</td>\n",
       "      <td>0.104495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>younger</td>\n",
       "      <td>0.811825</td>\n",
       "      <td>0.966028</td>\n",
       "      <td>0.154203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>old</td>\n",
       "      <td>0.825795</td>\n",
       "      <td>0.966028</td>\n",
       "      <td>0.140233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>asian</td>\n",
       "      <td>0.856335</td>\n",
       "      <td>0.966028</td>\n",
       "      <td>0.109694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>male</td>\n",
       "      <td>0.859259</td>\n",
       "      <td>0.966028</td>\n",
       "      <td>0.106770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>blind</td>\n",
       "      <td>0.856335</td>\n",
       "      <td>0.966028</td>\n",
       "      <td>0.109694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>female</td>\n",
       "      <td>0.843339</td>\n",
       "      <td>0.966028</td>\n",
       "      <td>0.122689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>catholic</td>\n",
       "      <td>0.823846</td>\n",
       "      <td>0.966028</td>\n",
       "      <td>0.142182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>trans</td>\n",
       "      <td>0.857309</td>\n",
       "      <td>0.966028</td>\n",
       "      <td>0.108719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>young</td>\n",
       "      <td>0.831319</td>\n",
       "      <td>0.966028</td>\n",
       "      <td>0.134710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>teenage</td>\n",
       "      <td>0.843014</td>\n",
       "      <td>0.966028</td>\n",
       "      <td>0.123014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>lgbt</td>\n",
       "      <td>0.811176</td>\n",
       "      <td>0.966028</td>\n",
       "      <td>0.154853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>white</td>\n",
       "      <td>0.857309</td>\n",
       "      <td>0.966028</td>\n",
       "      <td>0.108719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mexican</td>\n",
       "      <td>0.827745</td>\n",
       "      <td>0.966028</td>\n",
       "      <td>0.138284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>latino</td>\n",
       "      <td>0.870955</td>\n",
       "      <td>0.966028</td>\n",
       "      <td>0.095074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>hispanic</td>\n",
       "      <td>0.856335</td>\n",
       "      <td>0.966028</td>\n",
       "      <td>0.109694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>indian</td>\n",
       "      <td>0.811825</td>\n",
       "      <td>0.966028</td>\n",
       "      <td>0.154203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gay</td>\n",
       "      <td>0.825795</td>\n",
       "      <td>0.966028</td>\n",
       "      <td>0.140233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>american</td>\n",
       "      <td>0.815523</td>\n",
       "      <td>0.966028</td>\n",
       "      <td>0.150506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>lesbian</td>\n",
       "      <td>0.886549</td>\n",
       "      <td>0.966028</td>\n",
       "      <td>0.079479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>canadian</td>\n",
       "      <td>0.799805</td>\n",
       "      <td>0.966028</td>\n",
       "      <td>0.166224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>christian</td>\n",
       "      <td>0.829694</td>\n",
       "      <td>0.966028</td>\n",
       "      <td>0.136334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>straight</td>\n",
       "      <td>0.856660</td>\n",
       "      <td>0.966028</td>\n",
       "      <td>0.109369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>muslim</td>\n",
       "      <td>0.828719</td>\n",
       "      <td>0.966028</td>\n",
       "      <td>0.137309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>taoist</td>\n",
       "      <td>0.825795</td>\n",
       "      <td>0.966028</td>\n",
       "      <td>0.140233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>nonbinary</td>\n",
       "      <td>0.825795</td>\n",
       "      <td>0.966028</td>\n",
       "      <td>0.140233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>queer</td>\n",
       "      <td>0.884925</td>\n",
       "      <td>0.966028</td>\n",
       "      <td>0.081104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>heterosexual</td>\n",
       "      <td>0.877694</td>\n",
       "      <td>0.966028</td>\n",
       "      <td>0.088335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>transgender</td>\n",
       "      <td>0.840740</td>\n",
       "      <td>0.966028</td>\n",
       "      <td>0.125288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>japanese</td>\n",
       "      <td>0.824496</td>\n",
       "      <td>0.966028</td>\n",
       "      <td>0.141532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>millenial</td>\n",
       "      <td>0.823846</td>\n",
       "      <td>0.966028</td>\n",
       "      <td>0.142182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>latinx</td>\n",
       "      <td>0.825795</td>\n",
       "      <td>0.966028</td>\n",
       "      <td>0.140233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>homosexual</td>\n",
       "      <td>0.830898</td>\n",
       "      <td>0.966028</td>\n",
       "      <td>0.135130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>sikh</td>\n",
       "      <td>0.826120</td>\n",
       "      <td>0.966028</td>\n",
       "      <td>0.139908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>older</td>\n",
       "      <td>0.811825</td>\n",
       "      <td>0.966028</td>\n",
       "      <td>0.154203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>elderly</td>\n",
       "      <td>0.826445</td>\n",
       "      <td>0.966028</td>\n",
       "      <td>0.139583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>latina</td>\n",
       "      <td>0.841390</td>\n",
       "      <td>0.966028</td>\n",
       "      <td>0.124638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>paralyzed</td>\n",
       "      <td>0.825795</td>\n",
       "      <td>0.966028</td>\n",
       "      <td>0.140233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>buddhist</td>\n",
       "      <td>0.826770</td>\n",
       "      <td>0.966028</td>\n",
       "      <td>0.139258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>lgbtq</td>\n",
       "      <td>0.815399</td>\n",
       "      <td>0.966028</td>\n",
       "      <td>0.150629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>chinese</td>\n",
       "      <td>0.827420</td>\n",
       "      <td>0.966028</td>\n",
       "      <td>0.138608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>bisexual</td>\n",
       "      <td>0.885250</td>\n",
       "      <td>0.966028</td>\n",
       "      <td>0.080779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>deaf</td>\n",
       "      <td>0.843989</td>\n",
       "      <td>0.966028</td>\n",
       "      <td>0.122039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>european</td>\n",
       "      <td>0.823196</td>\n",
       "      <td>0.966028</td>\n",
       "      <td>0.142832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>african</td>\n",
       "      <td>0.825795</td>\n",
       "      <td>0.966028</td>\n",
       "      <td>0.140233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>protestant</td>\n",
       "      <td>0.840415</td>\n",
       "      <td>0.966028</td>\n",
       "      <td>0.125613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Identity_Titles      AUCt       AUC  AUC - AUCt\n",
       "0           jewish  0.830994  0.966028    0.135035\n",
       "1            black  0.861533  0.966028    0.104495\n",
       "2          younger  0.811825  0.966028    0.154203\n",
       "3              old  0.825795  0.966028    0.140233\n",
       "4            asian  0.856335  0.966028    0.109694\n",
       "5             male  0.859259  0.966028    0.106770\n",
       "6            blind  0.856335  0.966028    0.109694\n",
       "7           female  0.843339  0.966028    0.122689\n",
       "8         catholic  0.823846  0.966028    0.142182\n",
       "9            trans  0.857309  0.966028    0.108719\n",
       "10           young  0.831319  0.966028    0.134710\n",
       "11         teenage  0.843014  0.966028    0.123014\n",
       "12            lgbt  0.811176  0.966028    0.154853\n",
       "13           white  0.857309  0.966028    0.108719\n",
       "14         mexican  0.827745  0.966028    0.138284\n",
       "15          latino  0.870955  0.966028    0.095074\n",
       "16        hispanic  0.856335  0.966028    0.109694\n",
       "17          indian  0.811825  0.966028    0.154203\n",
       "18             gay  0.825795  0.966028    0.140233\n",
       "19        american  0.815523  0.966028    0.150506\n",
       "20         lesbian  0.886549  0.966028    0.079479\n",
       "21        canadian  0.799805  0.966028    0.166224\n",
       "22       christian  0.829694  0.966028    0.136334\n",
       "23        straight  0.856660  0.966028    0.109369\n",
       "24          muslim  0.828719  0.966028    0.137309\n",
       "25          taoist  0.825795  0.966028    0.140233\n",
       "26       nonbinary  0.825795  0.966028    0.140233\n",
       "27           queer  0.884925  0.966028    0.081104\n",
       "28    heterosexual  0.877694  0.966028    0.088335\n",
       "29     transgender  0.840740  0.966028    0.125288\n",
       "30        japanese  0.824496  0.966028    0.141532\n",
       "31       millenial  0.823846  0.966028    0.142182\n",
       "32          latinx  0.825795  0.966028    0.140233\n",
       "33      homosexual  0.830898  0.966028    0.135130\n",
       "34            sikh  0.826120  0.966028    0.139908\n",
       "35           older  0.811825  0.966028    0.154203\n",
       "36         elderly  0.826445  0.966028    0.139583\n",
       "37          latina  0.841390  0.966028    0.124638\n",
       "38       paralyzed  0.825795  0.966028    0.140233\n",
       "39        buddhist  0.826770  0.966028    0.139258\n",
       "40           lgbtq  0.815399  0.966028    0.150629\n",
       "41         chinese  0.827420  0.966028    0.138608\n",
       "42        bisexual  0.885250  0.966028    0.080779\n",
       "43            deaf  0.843989  0.966028    0.122039\n",
       "44        european  0.823196  0.966028    0.142832\n",
       "45         african  0.825795  0.966028    0.140233\n",
       "46      protestant  0.840415  0.966028    0.125613"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_auc = roc_auc_score(test_labels, SM_pred)\n",
    "terms_auc = []\n",
    "identity_terms = []\n",
    "for identity_term in set(terms):\n",
    "    term_data = df_test[df_test['Identity_Terms'] == identity_term].reset_index()\n",
    "    data = df_test.sample(n=len(term_data['Text']), random_state=0)\n",
    "    data = term_data.append(data, ignore_index=True)\n",
    "    y_true, y_pred = data['Label'].astype(int), data['prediction_scores']\n",
    "\n",
    "    try:\n",
    "        term_auc = roc_auc_score(y_true, y_pred.round())\n",
    "        terms_auc.append(term_auc)\n",
    "        identity_terms.append(identity_term)\n",
    "    except:\n",
    "        print(\"Error in \",identity_term)\n",
    "\n",
    "\n",
    "    \n",
    "eval_scores = pd.DataFrame(identity_terms, columns = ['Identity_Titles'])\n",
    "eval_scores['AUCt'] = terms_auc\n",
    "eval_scores['AUC'] = total_auc\n",
    "eval_scores['AUC - AUCt'] = abs(eval_scores['AUC'] - eval_scores['AUCt'])\n",
    "eval_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.044544566408519\n"
     ]
    }
   ],
   "source": [
    "print(eval_scores['AUC - AUCt'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
